<!DOCTYPE html>

<html lang="en" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>oneAPI DPC++ Compiler and Runtime architecture design &#8212; oneAPI DPC++ Compiler  documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=649a27d8" />
    <link rel="stylesheet" type="text/css" href="../_static/haiku.css?v=dfa0e015" />
    <script src="../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="SYCL Kernel Parameter Handling and Array Support" href="KernelParameterPassing.html" />
    <link rel="prev" title="SYCL Graph Usage Guide and Examples" href="../syclgraph/SYCLGraphUsageGuide.html" /> 
  </head><body>
      <div class="header" role="banner"><h1 class="heading"><a href="../index.html">
          <span>oneAPI DPC++ Compiler  documentation</span></a></h1>
        <h2 class="heading"><span>oneAPI DPC++ Compiler and Runtime architecture design</span></h2>
      </div>
      <div class="topnav" role="navigation" aria-label="top navigation">
      
        <p>
        «&#160;&#160;<a href="../syclgraph/SYCLGraphUsageGuide.html">SYCL Graph Usage Guide and Examples</a>
        &#160;&#160;::&#160;&#160;
        <a class="uplink" href="../index.html">Contents</a>
        &#160;&#160;::&#160;&#160;
        <a href="KernelParameterPassing.html">SYCL Kernel Parameter Handling and Array Support</a>&#160;&#160;»
        </p>

      </div>
      <div class="content" role="main">
        
        
  <section id="oneapi-dpc-compiler-and-runtime-architecture-design">
<h1>oneAPI DPC++ Compiler and Runtime architecture design<a class="headerlink" href="#oneapi-dpc-compiler-and-runtime-architecture-design" title="Link to this heading">¶</a></h1>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Link to this heading">¶</a></h2>
<p>This document describes the architecture of the DPC++ compiler and runtime
library. For DPC++ specification see
<a class="reference external" href="https://spec.oneapi.com/versions/latest/elements/dpcpp/source/index.html">spec</a>.</p>
</section>
<section id="dpc-compiler-architecture">
<h2>DPC++ Compiler architecture<a class="headerlink" href="#dpc-compiler-architecture" title="Link to this heading">¶</a></h2>
<p>DPC++ application compilation flow:</p>
<p><img alt="High level component diagram for DPC++ Compiler" src="../_images/Compiler-HLD.svg" /></p>
<p><em>Diagram 1. Application build flow.</em></p>
<p>DPC++ compiler logically can be split into the host compiler and a number of
device compilers—one per each supported target. Clang driver orchestrates the
compilation process, it will invoke the device compiler once per each requested
target, then it will invoke the host compiler to compile the host part of a
SYCL source. In the simplest case, when compilation and linkage are done in one
compiler driver invocation, once compilation is finished, the device object
files (which are really LLVM IR files) are linked with the <code class="docutils literal notranslate"><span class="pre">llvm-link</span></code> tool.
The resulting LLVM IR module is then translated into a SPIR-V module using the
<code class="docutils literal notranslate"><span class="pre">llvm-spirv</span></code> tool and wrapped in a host object file using the
<code class="docutils literal notranslate"><span class="pre">clang-offload-wrapper</span></code> tool. Once all the host object files and the wrapped
object with device code are ready, the driver invokes the usual platform linker
and the final executable called “fat binary” is produced. This is a host
executable or library with embedded linked images for each target specified at
the command line.</p>
<p>There are many variations of the compilation process depending on whether user
chose to do one or more of the following:</p>
<ul class="simple">
<li><p>perform compilation separately from linkage</p></li>
<li><p>compile the device SPIR-V module ahead-of-time for one or more targets</p></li>
<li><p>perform device code splitting so that device code is distributed across
multiple modules rather than enclosed in a single one</p></li>
<li><p>perform linkage of static device libraries
Sections below provide more details on some of those scenarios.</p></li>
</ul>
<p>SYCL sources can be also compiled as a regular C++ code, in this mode there is
no “device part” of the code — everything is executed on the host.</p>
<p>Device compiler is further split into the following major components:</p>
<ul class="simple">
<li><p><strong>Front-end</strong> - parses input source, “outlines” device part of the code,
applies additional restrictions on the device code (e.g. no exceptions or
virtual calls), generates LLVM IR for the device code only and “integration
header” which provides information like kernel name, parameters order and data
type for the runtime library.</p></li>
<li><p><strong>Middle-end</strong> - transforms the initial LLVM IR to get consumed by the
back-end. Today middle-end transformations include just a couple of passes:</p>
<ul>
<li><p>Optionally: Address space inference pass</p></li>
<li><p>TBD: potentially the middle-end optimizer can run any LLVM IR
transformation with only one limitation: back-end compiler should be able to
handle transformed LLVM IR.</p></li>
<li><p>Optionally: LLVM IR → SPIR-V translator.</p></li>
</ul>
</li>
<li><p><strong>Back-end</strong> - produces native “device” code. It is shown as
“Target-specific LLVM compiler” box on Diagram 1. It is invoked either at
compile time (in ahead-of-time compilation scenario) or at runtime
(in just-in-time compilation scenario).</p></li>
</ul>
<p><em>Design note: in current design we use SYCL device front-end compiler to produce the
integration header for two reasons. First, it must be possible to use any host
compiler to produce SYCL heterogeneous applications. Second, even if the
same clang compiler is used for the host compilation, information provided in the
integration header is used (included) by the SYCL runtime implementation, so the
header must be available before the host compilation starts.</em></p>
<section id="sycl-support-in-clang-front-end">
<h3>SYCL support in Clang front-end<a class="headerlink" href="#sycl-support-in-clang-front-end" title="Link to this heading">¶</a></h3>
<p>SYCL support in Clang front-end can be split into the following components:</p>
<ul class="simple">
<li><p>Device code outlining. This component is responsible for identifying and
outlining “device code” in the single source.</p></li>
<li><p>SYCL kernel function object (functor or lambda) lowering. This component
creates an OpenCL kernel function interface for SYCL kernels.</p></li>
<li><p>Device code diagnostics. This component enforces language restrictions on
device code.</p></li>
<li><p>Integration header generation. This component emits information required for
binding host and device parts of the SYCL code via OpenCL API.</p></li>
</ul>
<section id="device-code-outlining">
<h4>Device code outlining<a class="headerlink" href="#device-code-outlining" title="Link to this heading">¶</a></h4>
<p>Here is a code example of a SYCL program that demonstrates compiler outlining
work:</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="w"> </span><span class="nf">foo</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="o">++</span><span class="n">x</span><span class="p">;</span><span class="w"> </span><span class="p">}</span>
<span class="kt">int</span><span class="w"> </span><span class="nf">bar</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">throw</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">exception</span><span class="p">{</span><span class="s">&quot;CPU code only!&quot;</span><span class="p">};</span><span class="w"> </span><span class="p">}</span>
<span class="p">...</span>
<span class="k">using</span><span class="w"> </span><span class="k">namespace</span><span class="w"> </span><span class="nn">sycl</span><span class="p">;</span>
<span class="n">queue</span><span class="w"> </span><span class="n">Q</span><span class="p">;</span>
<span class="n">buffer</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="o">&gt;</span><span class="w"> </span><span class="n">a</span><span class="p">{</span><span class="n">range</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">{</span><span class="mi">1024</span><span class="p">}};</span>
<span class="n">Q</span><span class="p">.</span><span class="n">submit</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">handler</span><span class="o">&amp;</span><span class="w"> </span><span class="n">cgh</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="k">auto</span><span class="w"> </span><span class="n">A</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span><span class="p">.</span><span class="n">get_access</span><span class="o">&lt;</span><span class="n">access</span><span class="o">::</span><span class="n">mode</span><span class="o">::</span><span class="n">write</span><span class="o">&gt;</span><span class="p">(</span><span class="n">cgh</span><span class="p">);</span>
<span class="w">      </span><span class="n">cgh</span><span class="p">.</span><span class="n">parallel_for</span><span class="o">&lt;</span><span class="n">init_a</span><span class="o">&gt;</span><span class="p">(</span><span class="n">range</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">{</span><span class="mi">1024</span><span class="p">},</span><span class="w"> </span><span class="p">[</span><span class="o">=</span><span class="p">](</span><span class="n">id</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="w"> </span><span class="n">index</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">A</span><span class="p">[</span><span class="n">index</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">index</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">foo</span><span class="p">(</span><span class="mi">42</span><span class="p">);</span>
<span class="w">      </span><span class="p">});</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">...</span>
</pre></div>
</div>
<p>In this example, the compiler needs to compile the lambda expression passed
to the <code class="docutils literal notranslate"><span class="pre">sycl::handler::parallel_for</span></code> method, as well as the function <code class="docutils literal notranslate"><span class="pre">foo</span></code>
called from the lambda expression for the device.</p>
<p>The compiler must also ignore the <code class="docutils literal notranslate"><span class="pre">bar</span></code> function when we compile the
“device” part of the single source code, as it’s unused inside the device
portion of the source code (the contents of the lambda expression passed to the
<code class="docutils literal notranslate"><span class="pre">sycl::handler::parallel_for</span></code> and any function called from this lambda
expression).</p>
<p>The current approach is to use the SYCL kernel attribute in the runtime to
mark code passed to <code class="docutils literal notranslate"><span class="pre">sycl::handler::parallel_for</span></code> as “kernel functions”.
The runtime library can’t mark foo as “device” code - this is a compiler
job: to traverse all symbols accessible from kernel functions and add them to
the “device part” of the code marking them with the new SYCL device attribute.</p>
</section>
<section id="lowering-of-lambda-function-objects-and-named-function-objects">
<h4>Lowering of lambda function objects and named function objects<a class="headerlink" href="#lowering-of-lambda-function-objects-and-named-function-objects" title="Link to this heading">¶</a></h4>
<p>All SYCL memory objects shared between host and device (buffers/images,
these objects map to OpenCL buffers and images) must be accessed through special
<code class="docutils literal notranslate"><span class="pre">accessor</span></code> classes. The “device” side implementation of these classes contains
pointers to the device memory. As there is no way in OpenCL to pass structures
with pointers inside as kernel arguments all memory objects shared between host
and device must be passed to the kernel as raw pointers.</p>
<p>SYCL also has a special mechanism for passing kernel arguments from host to
the device. In OpenCL kernel arguments are set by calling <code class="docutils literal notranslate"><span class="pre">clSetKernelArg</span></code>
function for each kernel argument, meanwhile in SYCL all the kernel arguments
are fields of “SYCL kernel function” which can be defined as a lambda function
or a named function object and passed as an argument to SYCL function for
invoking kernels (such as <code class="docutils literal notranslate"><span class="pre">parallel_for</span></code> or <code class="docutils literal notranslate"><span class="pre">single_task</span></code>). For example, in the
previous code snippet above <code class="docutils literal notranslate"><span class="pre">accessor</span></code> <code class="docutils literal notranslate"><span class="pre">A</span></code> is one such captured kernel argument.</p>
<p>To facilitate the mapping of SYCL kernel data members to OpenCL
kernel arguments and overcome OpenCL limitations we added the generation of an
OpenCL kernel function inside the compiler. An OpenCL kernel function contains
the body of the SYCL kernel function, receives OpenCL-like parameters and
additionally does some manipulation to initialize SYCL kernel data members
with these parameters. In some pseudo code the OpenCL kernel function for the
previous code snippet above looks like this:</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// SYCL kernel is defined in SYCL headers:</span>
<span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">KernelName</span><span class="p">,</span><span class="w"> </span><span class="k">typename</span><span class="w"> </span><span class="nc">KernelType</span><span class="cm">/*, ...*/</span><span class="o">&gt;</span>
<span class="n">__attribute__</span><span class="p">((</span><span class="n">sycl_kernel</span><span class="p">))</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">sycl_kernel_function</span><span class="p">(</span><span class="n">KernelType</span><span class="w"> </span><span class="n">KernelFuncObj</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">// ...</span>
<span class="w">  </span><span class="n">KernelFuncObj</span><span class="p">();</span>
<span class="p">}</span>

<span class="c1">// Generated OpenCL kernel function</span>
<span class="n">__kernel</span><span class="w"> </span><span class="n">KernelName</span><span class="p">(</span><span class="n">global</span><span class="w"> </span><span class="kt">int</span><span class="o">*</span><span class="w"> </span><span class="n">a</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">KernelType</span><span class="w"> </span><span class="n">KernelFuncObj</span><span class="p">;</span><span class="w"> </span><span class="c1">// Actually kernel function object declaration</span>
<span class="w">  </span><span class="c1">// doesn&#39;t have a name in AST.</span>
<span class="w">  </span><span class="c1">// Let the kernel function object have one captured field - accessor A.</span>
<span class="w">  </span><span class="c1">// We need to init it with global pointer from arguments:</span>
<span class="w">  </span><span class="n">KernelFuncObj</span><span class="p">.</span><span class="n">A</span><span class="p">.</span><span class="n">__init</span><span class="p">(</span><span class="n">a</span><span class="p">);</span>
<span class="w">  </span><span class="c1">// Body of the SYCL kernel from SYCL headers:</span>
<span class="w">  </span><span class="p">{</span>
<span class="w">    </span><span class="n">KernelFuncObj</span><span class="p">();</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>OpenCL kernel function is generated by the compiler inside the Sema using AST
nodes. Additional details of kernel parameter passing may be found in the
document
<a class="reference internal" href="KernelParameterPassing.html"><span class="std std-doc">SYCL Kernel Parameter Handling and Array Support</span></a>.</p>
</section>
</section>
<section id="sycl-support-in-the-driver">
<h3>SYCL support in the driver<a class="headerlink" href="#sycl-support-in-the-driver" title="Link to this heading">¶</a></h3>
<p>SYCL offload support in the driver is based on the clang driver concepts and
defines:</p>
<ul class="simple">
<li><p>target triple and a native tool chain for each target (including “virtual”
targets like SPIR-V).</p></li>
<li><p>SYCL offload action based on generic offload action.</p></li>
</ul>
<p>SYCL compilation pipeline has a peculiarity compared to other compilation
scenarios - some of the actions in the pipeline may output multiple “clusters”
of files, consumed later by other actions. For example, each device binary maybe
accompanied by a symbol table and a specialization constant map - additional
information used by the SYCL runtime library - and it needs to be stored into
the device binary descriptor by the offload wrapper tool. With device code
splitting feature enabled, there can be multiple such sets (clusters) of files -
one per each separate device binary.</p>
<p>Current design of clang driver doesn’t allow to model that, namely:</p>
<ol class="arabic simple">
<li><p>Multiple inputs/outputs in the action graph.</p></li>
<li><p>Logical grouping of multiple inputs/outputs. For example, an input or output
can consist of multiple pairs of files, where each pair represents information
for a single device code module: [a file with device code, a file with exported
symbols].</p></li>
</ol>
<p>To support this, SYCL introduces the <code class="docutils literal notranslate"><span class="pre">file-table-tform</span></code> tool. This tool can
transform file tables following commands passed as input arguments. Each row
in the table represents a file cluster, each column - a type of data associated
with a cluster. The tool can replace and extract columns. For example, the
<code class="docutils literal notranslate"><span class="pre">sycl-post-link</span></code> tool can output two file clusters and the following file
table referencing all the files in the clusters:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>  <span class="p">[</span><span class="n">Code</span><span class="o">|</span><span class="n">Symbols</span><span class="o">|</span><span class="n">Properties</span><span class="p">]</span>
  <span class="n">a_0</span><span class="o">.</span><span class="n">bc</span><span class="o">|</span><span class="n">a_0</span><span class="o">.</span><span class="n">sym</span><span class="o">|</span><span class="n">a_0</span><span class="o">.</span><span class="n">props</span>
  <span class="n">a_1</span><span class="o">.</span><span class="n">bc</span><span class="o">|</span><span class="n">a_1</span><span class="o">.</span><span class="n">sym</span><span class="o">|</span><span class="n">a_1</span><span class="o">.</span><span class="n">props</span>
</pre></div>
</div>
<p>When participating in the action graph this tool inputs a file table
(<code class="docutils literal notranslate"><span class="pre">TY_Tempfiletable</span></code> clang input type) and/or a file list (<code class="docutils literal notranslate"><span class="pre">TY_Tempfilelist</span></code>),
performs requested transformations and outputs a file table or list. From the
clang design standpoint there is still single input and output, even though in
reality there are multiple.</p>
<p>For example, depending on compilation options, files from the “Code” column
above may need to undergo AOT compilation after the device code splitting step,
performed as a part of the code transformation sequence done by the
<code class="docutils literal notranslate"><span class="pre">sycl-post-link</span></code> tool. The driver will then:</p>
<ul class="simple">
<li><p>Use the <code class="docutils literal notranslate"><span class="pre">file-table-tform</span></code> to extract the code files and produce a file
list:</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">a_0</span><span class="o">.</span><span class="n">bc</span>
<span class="n">a_1</span><span class="o">.</span><span class="n">bc</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Pass this file list to the <code class="docutils literal notranslate"><span class="pre">llvm-foreach</span></code> tool along with AOT compilation
command to invoke it on every file in the list. This will result in another
file list</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">a_0</span><span class="o">.</span><span class="n">bin</span>
<span class="n">a_1</span><span class="o">.</span><span class="n">bin</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Then <code class="docutils literal notranslate"><span class="pre">file-table-tform</span></code> is invoked again to replace <code class="docutils literal notranslate"><span class="pre">.bc</span></code> with <code class="docutils literal notranslate"><span class="pre">.bin</span></code> in
the filetable to get a new filetable:</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>  <span class="p">[</span><span class="n">Code</span><span class="o">|</span><span class="n">Symbols</span><span class="o">|</span><span class="n">Properties</span><span class="p">]</span>
  <span class="n">a_0</span><span class="o">.</span><span class="n">bin</span><span class="o">|</span><span class="n">a_0</span><span class="o">.</span><span class="n">sym</span><span class="o">|</span><span class="n">a_0</span><span class="o">.</span><span class="n">props</span>
  <span class="n">a_1</span><span class="o">.</span><span class="n">bin</span><span class="o">|</span><span class="n">a_1</span><span class="o">.</span><span class="n">sym</span><span class="o">|</span><span class="n">a_1</span><span class="o">.</span><span class="n">props</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Finally, this filetable is passed to the <code class="docutils literal notranslate"><span class="pre">clang-offload-wrapper</span></code> tool to
construct a wrapper object which embeds all those files.</p></li>
</ul>
<p>Note that the graph does not change when more rows (clusters) or columns
(e.g. a “manifest” file) are added to the table.</p>
<section id="enable-sycl-offload">
<h4>Enable SYCL offload<a class="headerlink" href="#enable-sycl-offload" title="Link to this heading">¶</a></h4>
<p>To enable compilation following single-source multiple compiler-passes (SMCP)
technique which is described in the SYCL specification, a special option
must be passed to the clang driver:</p>
<p><code class="docutils literal notranslate"><span class="pre">-fsycl</span></code></p>
<p>With this option specified, the driver will invoke the host compiler and a
number of SYCL device compilers for targets specified in the <code class="docutils literal notranslate"><span class="pre">-fsycl-targets</span></code>
option. If <code class="docutils literal notranslate"><span class="pre">-fsycl-targets</span></code> is not specified, then single SPIR-V target is
assumed, and single device compiler for this target is invoked.</p>
<p>The option <code class="docutils literal notranslate"><span class="pre">-sycl-std</span></code> allows specifying which version of
the SYCL standard will be used for the compilation.
The default value for this option is <code class="docutils literal notranslate"><span class="pre">2020</span></code>.</p>
</section>
<section id="ahead-of-time-aot-compilation">
<h4>Ahead of time (AOT) compilation<a class="headerlink" href="#ahead-of-time-aot-compilation" title="Link to this heading">¶</a></h4>
<p>Ahead-of-time compilation is the process of invoking the back-end at compile
time to produce the final binary, as opposed to just-in-time (JIT) compilation
when final code generation is deferred until application runtime time.</p>
<p>AOT compilation reduces application execution time by skipping JIT compilation
and final device code can be tested before deploying.</p>
<p>JIT compilation provides portability of device code and target specific
optimizations.</p>
</section>
<section id="list-of-native-targets">
<h4>List of native targets<a class="headerlink" href="#list-of-native-targets" title="Link to this heading">¶</a></h4>
<p>The ahead-of-time compilation mode implies that there must be a way to specify
a set of target architectures for which to compile device code. By default, the
compiler generates SPIR-V and OpenCL device JIT compiler produces native target
binary.</p>
<p>To produce binaries for target architectures identified by target triples
<code class="docutils literal notranslate"><span class="pre">triple1</span></code> and <code class="docutils literal notranslate"><span class="pre">triple2</span></code>, the following SYCL compiler options are used:</p>
<p><code class="docutils literal notranslate"><span class="pre">-fsycl-targets=triple1,triple2</span></code></p>
<p>will produce binaries from SYCL kernels for devices identified by the two
target triples. This basically tells the driver which device compilers must be
invoked to compile the SYCL kernel code. By default, the JIT compilation
approach is assumed and device code is compiled for a single target triple -
<code class="docutils literal notranslate"><span class="pre">[spir,spir64]-*-*</span></code>.</p>
</section>
<section id="device-code-formats">
<h4>Device code formats<a class="headerlink" href="#device-code-formats" title="Link to this heading">¶</a></h4>
<p>Each target may support a number of code forms, each device compiler defines
and understands mnemonics designating a particular code form, for example
“<code class="docutils literal notranslate"><span class="pre">visa:3.3</span></code>” could designate virtual ISA version 3.3 for Intel GPU target (Gen
architecture). User can specify desired code format using the target-specific
option mechanism, similar to OpenMP.</p>
<p><code class="docutils literal notranslate"><span class="pre">-Xsycl-target-backend=&lt;triple&gt;</span> <span class="pre">&quot;arg1</span> <span class="pre">arg2</span> <span class="pre">...&quot;</span></code></p>
<p>For example, to support offload to Gen9/vISA3.3, the following options would be
used:</p>
<p><code class="docutils literal notranslate"><span class="pre">-fsycl</span> <span class="pre">-fsycl-targets=spir64_gen</span> <span class="pre">-Xsycl-target-backend</span> <span class="pre">&quot;-device</span> <span class="pre">skl&quot;</span></code></p>
<p>The driver passes the <code class="docutils literal notranslate"><span class="pre">-device</span> <span class="pre">skl</span></code> parameter directly to the Gen device backend
compiler <code class="docutils literal notranslate"><span class="pre">ocloc</span></code> without parsing it.</p>
<p><code class="docutils literal notranslate"><span class="pre">ocloc</span></code> is also capable of offline compilation for several ISA
versions/Gen architectures. For example, to make the device binary
compatible with all Intel Gen9 GPU platforms, one could use:</p>
<p><code class="docutils literal notranslate"><span class="pre">-fsycl</span> <span class="pre">-fsycl-targets=spir64_gen</span> <span class="pre">-Xsycl-target-backend</span> <span class="pre">&quot;-device</span> <span class="pre">gen9&quot;</span></code></p>
<p>For more details on supported platforms and argument syntax, refer to
the GPU offline compiler manual by detecting your local <code class="docutils literal notranslate"><span class="pre">ocloc</span></code>
installation and running <code class="docutils literal notranslate"><span class="pre">ocloc</span> <span class="pre">compile</span> <span class="pre">--help</span></code>.</p>
</section>
<section id="separate-compilation-and-linking">
<h4>Separate Compilation and Linking<a class="headerlink" href="#separate-compilation-and-linking" title="Link to this heading">¶</a></h4>
<p>The compiler supports such features as</p>
<ul class="simple">
<li><p>linking of device code obtained from different source files before generating
the final SPIR-V to be fed to the back-end.</p></li>
<li><p>splitting application build into separate compile and link steps.</p></li>
</ul>
<p>Overall build flow changes compared to the one shown on the Diagram 1
above in the following way.
<strong>Compilation step</strong> ends with engaging the offload
bundler to generate so-called “fat object” for each
&lt;host object, device code IR&gt; pair produced from the same heterogeneous source.
The fat object files become the result of compilation similar to object
files with usual non-offload compiler.
<strong>Link step</strong> starts with breaking the input fat objects back into their
constituents, then continue the same way as on the Diagram 1 - link host code
and device code separately and finally produce a “fat binary”.</p>
<p>The diagram below illustrates the changes in the build flow. The offload
bundler/unbundler actions are basically inserted between the <code class="docutils literal notranslate"><span class="pre">llvm-link</span></code> and
the <code class="docutils literal notranslate"><span class="pre">linker</span></code> invocations as shown on the Diagram 1.</p>
<p><img alt="Multi source compilation flow" src="../_images/SplitCompileAndLink.svg" />
<em>Diagram 2. Split compilation and linkage.</em></p>
<p><em>Current implementation uses LLVM IR as a default device binary format for <code class="docutils literal notranslate"><span class="pre">fat</span> <span class="pre">objects</span></code> and translates “linked LLVM IR” to SPIR-V. One of the reasons for this
decision is that SPIR-V doesn’t support linking template functions, which could
be defined in multiple modules and linker must resolve multiple definitions.
LLVM IR uses function attributes to satisfy “one definition rule”, which have
no counterparts in SPIR-V.</em></p>
</section>
<section id="fat-binary-creation-details">
<h4>Fat binary creation details<a class="headerlink" href="#fat-binary-creation-details" title="Link to this heading">¶</a></h4>
<p>“Fat binary” is a result of the final host linking step - this is a host binary
with device binary(s) embedded. When run, it automatically registers
all available device binaries within the SYCL runtime library. This section
describes how this is achieved.</p>
<p>The output fat binary is created with usual linker - e.g. <code class="docutils literal notranslate"><span class="pre">ld</span></code> on Linux and
<code class="docutils literal notranslate"><span class="pre">link.exe</span></code> on Windows. For the linker to be able to embed the device binaries,
they are first “wrapped” into a host object file called “wrapper object”. Then
this wrapper object is linked normally with the rest of host objects and/or
libraries.</p>
<p>The wrapper object is created by the <code class="docutils literal notranslate"><span class="pre">clang-offload-wrapper</span></code> tool, or simply
“offload wrapper”. The created wrapper object has two main components:</p>
<ol class="arabic simple">
<li><p>Global symbol - offload descriptor - pointing to a special data structure
put into in the object’s data section. It encompasses all needed information
about the wrapped device binaries - number of binaries, symbols each binary
defines, etc. - as well as the binaries themselves.</p></li>
<li><p>Registration/unregistration functions. The first one is put into a special
section so that it is invoked when the parent fat binary is loaded into a
process at runtime, the second one is put into another section to be invoked
when the parent fat binary is unloaded. The registration function basically
takes the pointer to the offload descriptor and invokes SYCL runtime library’s
registration function passing it as a parameter.</p></li>
</ol>
<p>The offload descriptor type hierarchy is described in the <code class="docutils literal notranslate"><span class="pre">pi.h</span></code> header. The
top-level structure is <code class="docutils literal notranslate"><span class="pre">pi_device_binaries_struct</span></code>.</p>
</section>
<section id="device-link">
<h4>Device Link<a class="headerlink" href="#device-link" title="Link to this heading">¶</a></h4>
<p>The -fsycl-link flag instructs the compiler to fully link device code without
fully linking host code. The result of such a compile is a fat object that
contains a fully linked device binary. The primary motivation for this flow
is to allow users to save re-compile time when making changes that only affect
their host code. In the case where device image generation takes a long time
(e.g. FPGA), this savings can be significant.</p>
<p>For example, if the user separated source code into four files: dev_a.cpp,
dev_b.cpp, host_a.cpp and host_b.cpp where only dev_a.cpp and dev_b.cpp contain
device code, they can divide the compilation process into three steps:</p>
<ol class="arabic simple">
<li><p>Device link: dev_a.cpp dev_b.cpp -&gt; dev_image.o (contain device image)</p></li>
<li><p>Host Compile (c): host_a.cpp -&gt; host_a.o; host_b.cpp -&gt; host_b.o</p></li>
<li><p>Linking: dev_image.o host_a.o host_b.o -&gt; executable</p></li>
</ol>
<p>Step 1 can take hours for some targets. But if the user wishes to recompile
after modifying only host_a.cpp and host_b.cpp, they can simply run steps 2 and
3 without rerunning the expensive step 1.</p>
<p>The compiler is responsible for verifying that the user provided all the
relevant files to the device link step. There are 2 cases that have to be
checked:</p>
<ol class="arabic simple">
<li><p>Missing symbols referenced by the kernels present in the device link step
(e.g. functions called by or global variables used by the known kernels).</p></li>
<li><p>Missing kernels.</p></li>
</ol>
<p>Case 1 can be identified in the device binary generation stage (step 1) by
scanning the known kernels. Case 2 must be verified by the driver by checking
for newly introduced kernels in the final link stage (step 3).</p>
</section>
<section id="device-link-during-compilation">
<h4>Device Link during compilation<a class="headerlink" href="#device-link-during-compilation" title="Link to this heading">¶</a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">-fno-sycl-rdc</span></code> flag can be used in combination with the <code class="docutils literal notranslate"><span class="pre">-c</span></code> option
when generating fat objects. This option combination informs the compiler to
perform a full device link stage against the device object, creating a fat
object that contains the corresponding host object and a fully compiled device
binary. It is expected that usage of <code class="docutils literal notranslate"><span class="pre">-fno-sycl-rdc</span></code> coincide with
ahead of time compiling.</p>
<p>When using the generated fat object in this case, the compiler will recognize
the fat object that contains the fully linked device binary. The device binary
will be unbundled and linked during the final host link and will not be sent
through any additional device linking steps.</p>
<ol class="arabic simple">
<li><p>Generation of fat object: a.cpp -&gt; a_fat.o (contains host object and full
device image)</p></li>
<li><p>Linking: a_fat.o -&gt; executable</p></li>
</ol>
<p>The generation of the full device image during the compilation (-c) step of
creating the object allows for library creation that does not require full
device linking steps which can be a burden to the user.  Providing these early
device linking steps give the provider of the archives/objects a better user
experience.</p>
</section>
<section id="device-code-post-link-step">
<h4>Device code post-link step<a class="headerlink" href="#device-code-post-link-step" title="Link to this heading">¶</a></h4>
<p>At link time all the device code is linked into
a single LLVM IR module unless <code class="docutils literal notranslate"><span class="pre">-fno-sycl-rdc</span></code> is specified.
<code class="docutils literal notranslate"><span class="pre">sycl-post-link</span></code> tool performs a number of final transformations on this LLVM IR
module before handing it off to the offload wrapper. Those include:</p>
<ul class="simple">
<li><p>device code splitting</p></li>
<li><p>symbol table generation</p></li>
<li><p>specialization constants lowering</p></li>
</ul>
<p>Depending on options, <code class="docutils literal notranslate"><span class="pre">sycl-post-link</span></code> can output either a single LLVM IR file,
or multiple files plus a file table referencing all of them. See the
“SYCL support in the driver” section for overall description of file table. The
diagram below shows possible clang action graphs which compilation process will
follow from the single linked LLVM IR module to creating the wrapper object.
There are multiple possible variants of the graph depending on:</p>
<ul class="simple">
<li><p>specific target requirements</p></li>
<li><p>device code splitting</p></li>
<li><p>AOT compilation</p></li>
</ul>
<p><img alt="Multi source compilation flow" src="../_images/DeviceLinkAndWrap.svg" /></p>
<p><em>Diagram 3. Device code link flows.</em></p>
<p>Colors of the graph’s edges show which paths are taken depending on the above
factors. Each edge is also annotated with the input/output file type.
The diagram does not show the <code class="docutils literal notranslate"><span class="pre">llvm-foreach</span></code> tool invocations for clarity.
This tool invokes given command line over each file in a file list. In this
diagram the tool is applied to <code class="docutils literal notranslate"><span class="pre">llvm-spirv</span></code> and AOT backend whenever the
input/output type is <code class="docutils literal notranslate"><span class="pre">TY_tempfilelist</span></code> and the target is not PTX.
Following this, <code class="docutils literal notranslate"><span class="pre">file-table-tform</span></code> takes two inputs - the file table and a file
list coming either from <code class="docutils literal notranslate"><span class="pre">llvm-spirv</span></code> or from the AOT backend.
Targeting PTX currently only accepts a single input file for processing, so
<code class="docutils literal notranslate"><span class="pre">file-table-tform</span></code> is used to extract the code file from the file table, which
is then processed by the
<a class="reference internal" href="#device-code-post-link-step-for-cuda">“PTX target processing” step</a>.
The resulting device binary is inserted back into the file table in place of the
extracted code file using <code class="docutils literal notranslate"><span class="pre">file-table-tform</span></code>. If <code class="docutils literal notranslate"><span class="pre">-fno-sycl-rdc</span></code> is specified,
all shown tools are invoked multiple times, once per translation unit rather than
once total. See <a class="reference internal" href="NonRelocatableDeviceCode.html"><span class="std std-doc">Non-Relocatable Device Code</span></a> for
more information.</p>
<section id="device-code-splitting">
<h5>Device code splitting<a class="headerlink" href="#device-code-splitting" title="Link to this heading">¶</a></h5>
<p>Putting all device code into a single SPIR-V module does not work well in the
following cases:</p>
<ol class="arabic simple">
<li><p>There are thousands of kernels defined and only small part of them is used at
run-time. Having them all in one SPIR-V module significantly increases JIT time.</p></li>
<li><p>Device code can be specialized for different devices. For example, kernels
that are supposed to be executed only on FPGA can use extensions available for
FPGA only. This will cause JIT compilation failure on other devices even if this
particular kernel is never called on them.</p></li>
</ol>
<p>To resolve these problems the compiler can split a single module into smaller
ones. The following features is supported:</p>
<ul class="simple">
<li><p>Emitting a separate module for source (translation unit)</p></li>
<li><p>Emitting a separate module for each kernel</p></li>
</ul>
<p>If the device code does not use <code class="docutils literal notranslate"><span class="pre">SYCL_EXTERNAL</span></code> functions, device code splitting
can be combined with the <code class="docutils literal notranslate"><span class="pre">-fno-sycl-rdc</span></code> option for improved compiler performance.</p>
<p>The current approach is:</p>
<ul class="simple">
<li><p>Generate special meta-data with translation unit ID for each kernel in SYCL
front-end. This ID will be used to group kernels on per-translation unit basis</p></li>
<li><p>Link all device LLVM modules using llvm-link</p></li>
<li><p>Perform split on a fully linked module, unless <code class="docutils literal notranslate"><span class="pre">-fno-sycl-rdc</span></code> is specified,
where splits are performed on a module containing only current translation unit and
linked device libraries</p></li>
<li><p>Generate a symbol table (list of kernels) for each produced device module for
proper module selection in runtime</p></li>
<li><p>Perform SPIR-V translation and AOT compilation (if requested) on each produced
module separately</p></li>
<li><p>Add information about presented kernels to a wrapping object for each device
image</p></li>
</ul>
<p>Device code splitting process:
<img alt="Device code splitting" src="../_images/DeviceCodeSplit.svg" /></p>
<p>The <code class="docutils literal notranslate"><span class="pre">llvm-link</span></code> box does not occur when <code class="docutils literal notranslate"><span class="pre">-fno-sycl-rdc</span></code> is specified. Rather,
all subsequent boxes occur per-source.</p>
<p>The “split” box is implemented as functionality of the dedicated tool
<code class="docutils literal notranslate"><span class="pre">sycl-post-link</span></code>. The tool runs a set of LLVM passes to split input module and
generates a symbol table (list of kernels) for each produced device module.</p>
<p>To enable device code split, a special option must be passed to the clang
driver:</p>
<p><code class="docutils literal notranslate"><span class="pre">-fsycl-device-code-split=&lt;value&gt;</span></code></p>
<p>There are three possible values for this option:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">per_source</span></code> - enables emitting a separate module for each source (translation
unit)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">per_kernel</span></code> - enables emitting a separate module for each kernel</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">off</span></code> - disables device code split. If <code class="docutils literal notranslate"><span class="pre">-fno-sycl-rdc</span></code> is specified, the behavior is
the same as <code class="docutils literal notranslate"><span class="pre">per_source</span></code></p></li>
</ul>
</section>
<section id="symbol-table-generation">
<h5>Symbol table generation<a class="headerlink" href="#symbol-table-generation" title="Link to this heading">¶</a></h5>
<p>TBD</p>
</section>
<section id="specialization-constants-lowering">
<h5>Specialization constants lowering<a class="headerlink" href="#specialization-constants-lowering" title="Link to this heading">¶</a></h5>
<p>See corresponding documentation</p>
</section>
</section>
<section id="cuda-support">
<h4>CUDA support<a class="headerlink" href="#cuda-support" title="Link to this heading">¶</a></h4>
<p>The driver supports compilation to NVPTX when the <code class="docutils literal notranslate"><span class="pre">nvptx64-nvidia-cuda</span></code> is
passed to <code class="docutils literal notranslate"><span class="pre">-fsycl-targets</span></code>.</p>
<p>Unlike other AOT targets, the bitcode module linked from intermediate compiled
objects never goes through SPIR-V. Instead it is passed directly in bitcode form
down to the NVPTX Back End. All produced bitcode depends on two libraries,
<code class="docutils literal notranslate"><span class="pre">libdevice.bc</span></code> (provided by the CUDA SDK) and <code class="docutils literal notranslate"><span class="pre">libspirv-nvptx64--nvidiacl.bc</span></code> variants
(built by the libclc project). <code class="docutils literal notranslate"><span class="pre">libspirv-nvptx64--nvidiacl.bc</span></code> is not used directly.
Instead it is used to generate remangled variants
<code class="docutils literal notranslate"><span class="pre">remangled-l64-signed_char.libspirv-nvptx64--nvidiacl.bc</span></code> and
<code class="docutils literal notranslate"><span class="pre">remangled-l32-signed_char.libspirv-nvptx64--nvidiacl.bc</span></code> to handle primitive type
differences between Linux and Windows.</p>
<section id="device-code-post-link-step-for-cuda">
<h5>Device code post-link step for CUDA<a class="headerlink" href="#device-code-post-link-step-for-cuda" title="Link to this heading">¶</a></h5>
<p>During the “PTX target processing” in the device linking step <a class="reference internal" href="#device-code-post-link-step">Device
code post-link step</a>, the llvm bitcode
objects for the CUDA target are linked together during the common
<code class="docutils literal notranslate"><span class="pre">llvm-link</span></code> step and then split using the <code class="docutils literal notranslate"><span class="pre">sycl-post-link</span></code> tool.
For each temporary bitcode file, clang is invoked for the temporary file to link
<code class="docutils literal notranslate"><span class="pre">libspirv-nvptx64--nvidiacl.bc</span></code> and <code class="docutils literal notranslate"><span class="pre">libdevice.bc</span></code> and compile the resulting
module to PTX using the NVPTX backend. The resulting PTX file is assembled
into a cubin using the <code class="docutils literal notranslate"><span class="pre">ptxas</span></code> tool (part of the CUDA SDK). The PTX file and
cubin are assembled together using <code class="docutils literal notranslate"><span class="pre">fatbinary</span></code> to produce a CUDA fatbin.
The produced CUDA fatbins then replace the llvm bitcode files in the file table generated
by <code class="docutils literal notranslate"><span class="pre">sycl-post-link</span></code>. The resulting table is passed to the offload wrapper tool.</p>
<p><img alt="NVPTX AOT build" src="../_images/DevicePTXProcessing.svg" /></p>
</section>
<section id="checking-if-the-compiler-is-targeting-nvptx">
<h5>Checking if the compiler is targeting NVPTX<a class="headerlink" href="#checking-if-the-compiler-is-targeting-nvptx" title="Link to this heading">¶</a></h5>
<p>When the SYCL compiler is in device mode and targeting the NVPTX backend,
the compiler defines <code class="docutils literal notranslate"><span class="pre">__SYCL_DEVICE_ONLY__</span></code> and <code class="docutils literal notranslate"><span class="pre">__NVPTX__</span></code> macros. This
macro combination can safely be used to enable NVPTX specific code
path in SYCL kernels.</p>
<p><em>Note: these macros are defined only during the device compilation phase.</em></p>
</section>
<section id="nvptx-builtins">
<h5>NVPTX Builtins<a class="headerlink" href="#nvptx-builtins" title="Link to this heading">¶</a></h5>
<p>Builtins are implemented in OpenCL C within libclc. OpenCL C treats <code class="docutils literal notranslate"><span class="pre">long</span></code>
types as 64 bit and has no <code class="docutils literal notranslate"><span class="pre">long</span> <span class="pre">long</span></code> types while Windows DPC++ treats <code class="docutils literal notranslate"><span class="pre">long</span></code>
types like 32-bit integers and <code class="docutils literal notranslate"><span class="pre">long</span> <span class="pre">long</span></code> types like 64-bit integers.
Differences between the primitive types can cause applications to use
incompatible libclc built-ins. A remangler creates multiple libspirv files
with different remangled function names to support both Windows and Linux.
When building a SYCL application targeting the CUDA backend the driver
will link the device code with
<code class="docutils literal notranslate"><span class="pre">remangled-l32-signed_char.libspirv-nvptx64--nvidiacl.bc</span></code> if the host target is
Windows or it will link the device code with
<code class="docutils literal notranslate"><span class="pre">remangled-l64-signed_char.libspirv-nvptx64--nvidiacl.bc</span></code> if the host target is
Linux.</p>
<p>When the SYCL compiler is in device mode and targeting the NVPTX backend, the
compiler exposes NVPTX builtins supported by clang.</p>
<p><em>Note: this enable NVPTX specific features which cannot be supported by other
targets or the host.</em></p>
<p>Example:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">double</span><span class="w"> </span><span class="nf">my_min</span><span class="p">(</span><span class="kt">double</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">y</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="cp">#if defined(__NVPTX__) &amp;&amp; defined(__SYCL_DEVICE_ONLY__)</span>
<span class="w">  </span><span class="c1">// Only available if in device mode and</span>
<span class="w">  </span><span class="c1">// while compiling for the NVPTX target.</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">__nvvm_fmin_d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">);</span>
<span class="cp">#else</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">y</span><span class="p">;</span>
<span class="cp">#endif</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="local-memory-support">
<h5>Local memory support<a class="headerlink" href="#local-memory-support" title="Link to this heading">¶</a></h5>
<p>In CUDA, users can only allocate one chunk of host allocated shared memory
(which maps to SYCL’s local accessors). This chunk of memory is allocated as an
array <code class="docutils literal notranslate"><span class="pre">extern</span> <span class="pre">__shared__</span> <span class="pre">&lt;type&gt;</span> <span class="pre">&lt;name&gt;[];</span></code> which LLVM represents as an external
global symbol to the CUDA shared memory address space. The NVPTX backend then
lowers this into a <code class="docutils literal notranslate"><span class="pre">.extern</span> <span class="pre">.shared</span> <span class="pre">.align</span> <span class="pre">4</span> <span class="pre">.b8</span></code> PTX instruction.</p>
<p>In SYCL, users can allocate multiple local accessors and pass them as kernel
parameters. When the SYCL frontend lowers the SYCL kernel invocation into an
OpenCL compliant kernel entry, it lowers local accessors into a pointer to
OpenCL local memory (CUDA shared memory) but this is not legal for CUDA kernels.</p>
<p>To legalize the SYCL lowering for CUDA, a SYCL for CUDA specific pass will do
the following:</p>
<ul class="simple">
<li><p>Create a global symbol to the CUDA shared memory address space</p></li>
<li><p>Transform all pointers to CUDA shared memory into a 32 bit integer
representing the offset in bytes to use with the global symbol</p></li>
<li><p>Replace all uses of the transformed pointers by the address to global symbol
offset by the value of the integer passed as parameter</p></li>
</ul>
<p>As an example, the following kernel:</p>
<div class="highlight-LLVM notranslate"><div class="highlight"><pre><span></span><span class="k">define</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="vg">@SYCL_generated_kernel</span><span class="p">(</span><span class="kt">i64</span><span class="w"> </span><span class="k">addrspace</span><span class="p">(</span><span class="m">3</span><span class="p">)*</span><span class="w"> </span><span class="k">nocapture</span><span class="w"> </span><span class="nv">%local_ptr</span><span class="p">,</span><span class="w"> </span><span class="kt">i32</span><span class="w"> </span><span class="nv">%arg</span><span class="p">,</span><span class="w"> </span><span class="kt">i64</span><span class="w"> </span><span class="k">addrspace</span><span class="p">(</span><span class="m">3</span><span class="p">)*</span><span class="w"> </span><span class="k">nocapture</span><span class="w"> </span><span class="nv">%local_ptr2</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="nv nv-Anonymous">%0</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="k">load</span><span class="w"> </span><span class="kt">i64</span><span class="p">,</span><span class="w"> </span><span class="kt">i64</span><span class="w"> </span><span class="k">addrspace</span><span class="p">(</span><span class="m">3</span><span class="p">)*</span><span class="w"> </span><span class="nv">%local_ptr</span>
<span class="w">  </span><span class="nv nv-Anonymous">%1</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="k">load</span><span class="w"> </span><span class="kt">i64</span><span class="p">,</span><span class="w"> </span><span class="kt">i64</span><span class="w"> </span><span class="k">addrspace</span><span class="p">(</span><span class="m">3</span><span class="p">)*</span><span class="w"> </span><span class="nv">%local_ptr2</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Is transformed into this kernel when targeting CUDA:</p>
<div class="highlight-LLVM notranslate"><div class="highlight"><pre><span></span><span class="vg">@SYCL_generated_kernel.shared_mem</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="k">external</span><span class="w"> </span><span class="k">dso_local</span><span class="w"> </span><span class="k">local_unnamed_addr</span><span class="w"> </span><span class="k">addrspace</span><span class="p">(</span><span class="m">3</span><span class="p">)</span><span class="w"> </span><span class="k">global</span><span class="w"> </span><span class="p">[</span><span class="m">0</span><span class="w"> </span><span class="k">x</span><span class="w"> </span><span class="kt">i8</span><span class="p">],</span><span class="w"> </span><span class="k">align</span><span class="w"> </span><span class="m">4</span>

<span class="k">define</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="vg">@SYCL_generated_kernel</span><span class="p">(</span><span class="kt">i32</span><span class="w"> </span><span class="nv">%local_ptr_offset</span><span class="p">,</span><span class="w"> </span><span class="kt">i32</span><span class="w"> </span><span class="nv">%arg</span><span class="p">,</span><span class="w"> </span><span class="kt">i32</span><span class="w"> </span><span class="nv">%local_ptr_offset2</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="nv">%new_local_ptr</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="k">getelementptr</span><span class="w"> </span><span class="k">inbounds</span><span class="w"> </span><span class="p">[</span><span class="m">0</span><span class="w"> </span><span class="k">x</span><span class="w"> </span><span class="kt">i8</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="m">0</span><span class="w"> </span><span class="k">x</span><span class="w"> </span><span class="kt">i8</span><span class="p">]</span><span class="w"> </span><span class="k">addrspace</span><span class="p">(</span><span class="m">3</span><span class="p">)*</span><span class="w"> </span><span class="vg">@SYCL_generated_kernel.shared_mem</span><span class="p">,</span><span class="w"> </span><span class="kt">i32</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="kt">i32</span><span class="w"> </span><span class="nv">%local_ptr_offset</span>
<span class="w">  </span><span class="nv">%new_local_ptr2</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="k">getelementptr</span><span class="w"> </span><span class="k">inbounds</span><span class="w"> </span><span class="p">[</span><span class="m">0</span><span class="w"> </span><span class="k">x</span><span class="w"> </span><span class="kt">i8</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="m">0</span><span class="w"> </span><span class="k">x</span><span class="w"> </span><span class="kt">i8</span><span class="p">]</span><span class="w"> </span><span class="k">addrspace</span><span class="p">(</span><span class="m">3</span><span class="p">)*</span><span class="w"> </span><span class="vg">@SYCL_generated_kernel.shared_mem</span><span class="p">,</span><span class="w"> </span><span class="kt">i32</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="kt">i32</span><span class="w"> </span><span class="nv">%local_ptr_offset2</span>
<span class="w">  </span><span class="nv nv-Anonymous">%0</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="k">load</span><span class="w"> </span><span class="kt">i32</span><span class="p">,</span><span class="w"> </span><span class="kt">i32</span><span class="w"> </span><span class="k">addrspace</span><span class="p">(</span><span class="m">3</span><span class="p">)*</span><span class="w"> </span><span class="nv">%new_local_ptr</span>
<span class="w">  </span><span class="nv nv-Anonymous">%1</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="k">load</span><span class="w"> </span><span class="kt">i64</span><span class="p">,</span><span class="w"> </span><span class="kt">i64</span><span class="w"> </span><span class="k">addrspace</span><span class="p">(</span><span class="m">3</span><span class="p">)*</span><span class="w"> </span><span class="nv">%new_local_ptr2</span>
<span class="p">}</span>
</pre></div>
</div>
<p>On the runtime side, when setting local memory arguments, the CUDA PI
implementation will internally set the argument as the offset with respect to
the accumulated size of used local memory. This approach preserves the existing
PI interface.</p>
</section>
<section id="global-offset-support">
<h5>Global offset support<a class="headerlink" href="#global-offset-support" title="Link to this heading">¶</a></h5>
<p>The CUDA API does not natively support the global offset parameter
expected by the SYCL.</p>
<p>In order to emulate this and make generated kernel compliant, an intrinsic
<code class="docutils literal notranslate"><span class="pre">llvm.nvvm.implicit.offset</span></code> (clang builtin <code class="docutils literal notranslate"><span class="pre">__builtin_ptx_implicit_offset</span></code>) was
introduced materializing the use of this implicit parameter for the NVPTX
backend. AMDGCN uses the same approach with <code class="docutils literal notranslate"><span class="pre">llvm.amdgpu.implicit.offset</span></code> and
<code class="docutils literal notranslate"><span class="pre">__builtin_amdgcn_implicit_offset</span></code>. The intrinsic returns a pointer to <code class="docutils literal notranslate"><span class="pre">i32</span></code>
referring to a 3 elements array.</p>
<p>Each non-kernel function reaching the implicit offset intrinsic in the
call graph is augmented with an extra implicit parameter of type
pointer to <code class="docutils literal notranslate"><span class="pre">i32</span></code>. Kernels calling one of these functions using
this intrinsic are cloned:</p>
<ul class="simple">
<li><p>the original kernel initializes an array of 3 <code class="docutils literal notranslate"><span class="pre">i32</span></code> to 0 and passes
the pointer to this array to each function with the implicit
parameter;</p></li>
<li><p>the cloned function type is augmented with an implicit parameter of
type array of 3 <code class="docutils literal notranslate"><span class="pre">i32</span></code>. The pointer to this array is then passed each
function with the implicit parameter.</p></li>
</ul>
<p>The runtime will query both kernels and call the appropriate one based
on the following logic:</p>
<ul class="simple">
<li><p>If the 2 versions exist, the original kernel is called if global
offset is 0 otherwise it will call the cloned one and pass the
offset by value (for CUDA backend), or by ref for AMD;</p></li>
<li><p>If only 1 function exist, it is assumed that the kernel makes no use
of this parameter and therefore ignores it.</p></li>
</ul>
<p>As an example, the following code:</p>
<div class="highlight-LLVM notranslate"><div class="highlight"><pre><span></span><span class="k">declare</span><span class="w"> </span><span class="kt">i32</span><span class="p">*</span><span class="w"> </span><span class="vg">@llvm.nvvm.implicit.offset</span><span class="p">()</span>

<span class="k">define</span><span class="w"> </span><span class="k">weak_odr</span><span class="w"> </span><span class="k">dso_local</span><span class="w"> </span><span class="kt">i64</span><span class="w"> </span><span class="vg">@other_function</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="nv nv-Anonymous">%1</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="k">tail</span><span class="w"> </span><span class="k">call</span><span class="w"> </span><span class="kt">i32</span><span class="p">*</span><span class="w"> </span><span class="vg">@llvm.nvvm.implicit.offset</span><span class="p">()</span>
<span class="w">  </span><span class="nv nv-Anonymous">%2</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="k">getelementptr</span><span class="w"> </span><span class="k">inbounds</span><span class="w"> </span><span class="kt">i32</span><span class="p">,</span><span class="w"> </span><span class="kt">i32</span><span class="p">*</span><span class="w"> </span><span class="nv nv-Anonymous">%1</span><span class="p">,</span><span class="w"> </span><span class="kt">i64</span><span class="w"> </span><span class="m">2</span>
<span class="w">  </span><span class="nv nv-Anonymous">%3</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="k">load</span><span class="w"> </span><span class="kt">i32</span><span class="p">,</span><span class="w"> </span><span class="kt">i32</span><span class="p">*</span><span class="w"> </span><span class="nv nv-Anonymous">%2</span><span class="p">,</span><span class="w"> </span><span class="k">align</span><span class="w"> </span><span class="m">4</span>
<span class="w">  </span><span class="nv nv-Anonymous">%4</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="k">zext</span><span class="w"> </span><span class="kt">i32</span><span class="w"> </span><span class="nv nv-Anonymous">%3</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="kt">i64</span>
<span class="w">  </span><span class="k">ret</span><span class="w"> </span><span class="kt">i64</span><span class="w"> </span><span class="nv nv-Anonymous">%4</span>
<span class="p">}</span>

<span class="k">define</span><span class="w"> </span><span class="k">weak_odr</span><span class="w"> </span><span class="k">dso_local</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="vg">@other_function2</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">ret</span>
<span class="p">}</span>

<span class="k">define</span><span class="w"> </span><span class="k">weak_odr</span><span class="w"> </span><span class="k">dso_local</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="vg">@example_kernel</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="nl">entry:</span>
<span class="w">  </span><span class="nv nv-Anonymous">%0</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="k">call</span><span class="w"> </span><span class="kt">i64</span><span class="w"> </span><span class="vg">@other_function</span><span class="p">()</span>
<span class="w">  </span><span class="k">call</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="vg">@other_function2</span><span class="p">()</span>
<span class="w">  </span><span class="k">ret</span><span class="w"> </span><span class="k">void</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Is transformed into this:</p>
<div class="highlight-LLVM notranslate"><div class="highlight"><pre><span></span><span class="k">define</span><span class="w"> </span><span class="k">weak_odr</span><span class="w"> </span><span class="k">dso_local</span><span class="w"> </span><span class="kt">i64</span><span class="w"> </span><span class="vg">@other_function</span><span class="p">(</span><span class="kt">i32</span><span class="p">*</span><span class="w"> </span><span class="nv nv-Anonymous">%0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="nv nv-Anonymous">%2</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="k">getelementptr</span><span class="w"> </span><span class="k">inbounds</span><span class="w"> </span><span class="kt">i32</span><span class="p">,</span><span class="w"> </span><span class="kt">i32</span><span class="p">*</span><span class="w"> </span><span class="nv nv-Anonymous">%0</span><span class="p">,</span><span class="w"> </span><span class="kt">i64</span><span class="w"> </span><span class="m">2</span>
<span class="w">  </span><span class="nv nv-Anonymous">%3</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="k">load</span><span class="w"> </span><span class="kt">i32</span><span class="p">,</span><span class="w"> </span><span class="kt">i32</span><span class="p">*</span><span class="w"> </span><span class="nv nv-Anonymous">%2</span><span class="p">,</span><span class="w"> </span><span class="k">align</span><span class="w"> </span><span class="m">4</span>
<span class="w">  </span><span class="nv nv-Anonymous">%4</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="k">zext</span><span class="w"> </span><span class="kt">i32</span><span class="w"> </span><span class="nv nv-Anonymous">%3</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="kt">i64</span>

<span class="w">  </span><span class="k">ret</span><span class="w"> </span><span class="kt">i64</span><span class="w"> </span><span class="nv nv-Anonymous">%4</span>
<span class="p">}</span>

<span class="k">define</span><span class="w"> </span><span class="k">weak_odr</span><span class="w"> </span><span class="k">dso_local</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="vg">@example_kernel</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="nl">entry:</span>
<span class="w">  </span><span class="nv nv-Anonymous">%0</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="k">alloca</span><span class="w"> </span><span class="p">[</span><span class="m">3</span><span class="w"> </span><span class="k">x</span><span class="w"> </span><span class="kt">i32</span><span class="p">],</span><span class="w"> </span><span class="k">align</span><span class="w"> </span><span class="m">4</span>
<span class="w">  </span><span class="nv nv-Anonymous">%1</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="k">bitcast</span><span class="w"> </span><span class="p">[</span><span class="m">3</span><span class="w"> </span><span class="k">x</span><span class="w"> </span><span class="kt">i32</span><span class="p">]*</span><span class="w"> </span><span class="nv nv-Anonymous">%0</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="kt">i8</span><span class="p">*</span>
<span class="w">  </span><span class="k">call</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="vg">@llvm.memset.p0i8.i64</span><span class="p">(</span><span class="kt">i8</span><span class="p">*</span><span class="w"> </span><span class="k">nonnull</span><span class="w"> </span><span class="k">align</span><span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="k">dereferenceable</span><span class="p">(</span><span class="m">12</span><span class="p">)</span><span class="w"> </span><span class="nv nv-Anonymous">%1</span><span class="p">,</span><span class="w"> </span><span class="kt">i8</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="kt">i64</span><span class="w"> </span><span class="m">12</span><span class="p">,</span><span class="w"> </span><span class="kt">i1</span><span class="w"> </span><span class="k">false</span><span class="p">)</span>
<span class="w">  </span><span class="nv nv-Anonymous">%2</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="k">getelementptr</span><span class="w"> </span><span class="k">inbounds</span><span class="w"> </span><span class="p">[</span><span class="m">3</span><span class="w"> </span><span class="k">x</span><span class="w"> </span><span class="kt">i32</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="m">3</span><span class="w"> </span><span class="k">x</span><span class="w"> </span><span class="kt">i32</span><span class="p">]*</span><span class="w"> </span><span class="nv nv-Anonymous">%0</span><span class="p">,</span><span class="w"> </span><span class="kt">i32</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="kt">i32</span><span class="w"> </span><span class="m">0</span>
<span class="w">  </span><span class="nv nv-Anonymous">%3</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="k">call</span><span class="w"> </span><span class="kt">i64</span><span class="w"> </span><span class="vg">@other_function</span><span class="p">(</span><span class="kt">i32</span><span class="p">*</span><span class="w"> </span><span class="nv nv-Anonymous">%2</span><span class="p">)</span>
<span class="w">  </span><span class="k">call</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="vg">@other_function2</span><span class="p">()</span>
<span class="w">  </span><span class="k">ret</span><span class="w"> </span><span class="k">void</span>
<span class="p">}</span>

<span class="k">define</span><span class="w"> </span><span class="k">weak_odr</span><span class="w"> </span><span class="k">dso_local</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="vg">@example_kernel_with_offset</span><span class="p">([</span><span class="m">3</span><span class="w"> </span><span class="k">x</span><span class="w"> </span><span class="kt">i32</span><span class="p">]*</span><span class="w"> </span><span class="k">byval</span><span class="p">([</span><span class="m">3</span><span class="w"> </span><span class="k">x</span><span class="w"> </span><span class="kt">i32</span><span class="p">])</span><span class="w"> </span><span class="nv nv-Anonymous">%0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="nl">entry:</span>
<span class="w">  </span><span class="nv nv-Anonymous">%1</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="k">bitcast</span><span class="w"> </span><span class="p">[</span><span class="m">3</span><span class="w"> </span><span class="k">x</span><span class="w"> </span><span class="kt">i32</span><span class="p">]*</span><span class="w"> </span><span class="nv nv-Anonymous">%0</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="kt">i32</span><span class="p">*</span>
<span class="w">  </span><span class="nv nv-Anonymous">%2</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="k">call</span><span class="w"> </span><span class="kt">i64</span><span class="w"> </span><span class="vg">@other_function</span><span class="p">(</span><span class="kt">i32</span><span class="p">*</span><span class="w"> </span><span class="nv nv-Anonymous">%1</span><span class="p">)</span>
<span class="w">  </span><span class="k">call</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="vg">@other_function2</span><span class="p">()</span>
<span class="w">  </span><span class="k">ret</span><span class="w"> </span><span class="k">void</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Note: Kernel naming is not fully stable for now.</p>
</section>
<section id="kernel-fusion-support">
<h5>Kernel Fusion Support<a class="headerlink" href="#kernel-fusion-support" title="Link to this heading">¶</a></h5>
<p>The <a class="reference download internal" download="" href="../_downloads/2c8b61d471b5bc20d05508d865b68770/sycl_ext_codeplay_kernel_fusion.asciidoc"><span class="xref download myst">experimental kernel fusion
extension</span></a>
also supports the CUDA and HIP backends. However, as the CUBIN, PTX and AMD assembly
are not suitable input formats for the <a class="reference internal" href="KernelFusionJIT.html"><span class="std std-doc">kernel fusion JIT compiler</span></a>, a
suitable IR has to be added as an additional device binary.</p>
<p>Therefore, in case kernel fusion should be performed for the CUDA or HIP backends, the
user needs to specify the additional flag <code class="docutils literal notranslate"><span class="pre">-fsycl-embed-ir</span></code> during compilation,
to add LLVM IR as an additional device binary. When the flag <code class="docutils literal notranslate"><span class="pre">-fsycl-embed-ir</span></code>
is specified, the LLVM IR produced by Clang for the CUDA/HIP backend device
compilation is added to the fat binary file. To this end, the resulting
file-table from <code class="docutils literal notranslate"><span class="pre">sycl-post-link</span></code> is additionally passed to the
<code class="docutils literal notranslate"><span class="pre">clang-offload-wrapper</span></code>, creating a wrapper object with target <code class="docutils literal notranslate"><span class="pre">llvm_nvptx64</span></code>
for the CUDA backend and <code class="docutils literal notranslate"><span class="pre">llvm_amdgcn</span></code> for the HIP backend.</p>
<p>This device binary in LLVM IR format can be retrieved by the SYCL runtime and
used by the kernel fusion JIT compiler. For the CUDA backend, the resulting fused
kernel is compiled to PTX assembly by the kernel fusion JIT compiler at runtime.
For the HIP backend, the resulting fused kernel is compiled to an AMDGCN binary
by the kernel fusion JIT compiler at runtime, however this output requires
finalization by <code class="docutils literal notranslate"><span class="pre">lld</span></code>. Rather than adding another dependancy to the fusion jit,
a <code class="docutils literal notranslate"><span class="pre">Requires</span> <span class="pre">finalization</span></code> property is added the binary. The HIP
PI plugin/UR adapter will then use the AMD Compiler Object Manager library
(<code class="docutils literal notranslate"><span class="pre">comgr</span></code>, part of the ROCm package) in order to finalize it into
a loadable format.</p>
<p>Note that the device binary in LLVM IR does not replace the device binary in
target format, but is embed in addition to it.</p>
</section>
</section>
</section>
<section id="integration-with-spir-v-format">
<h3>Integration with SPIR-V format<a class="headerlink" href="#integration-with-spir-v-format" title="Link to this heading">¶</a></h3>
<p>This section explains how to generate SPIR-V specific types and operations from
C++ classes and functions.</p>
<p>Translation of SYCL C++ programs to the code executable on heterogeneous
systems can be considered as three step process:</p>
<ol class="arabic simple">
<li><p>translation of SYCL C++ programs into LLVM IR</p></li>
<li><p>translation from LLVM IR to SPIR-V</p></li>
<li><p>translation from SPIR-V to machine code</p></li>
</ol>
<p>LLVM-IR to SPIR-V translation is performed by a dedicated tool -
<a class="reference external" href="https://github.com/KhronosGroup/SPIRV-LLVM-Translator">translator</a>.
This tool correctly translates most of regular LLVM IR types/operations/etc to
SPIR-V.</p>
<p>For example:</p>
<ul class="simple">
<li><p>Type: <code class="docutils literal notranslate"><span class="pre">i32</span></code> → <code class="docutils literal notranslate"><span class="pre">OpTypeInt</span></code></p></li>
<li><p>Operation: <code class="docutils literal notranslate"><span class="pre">load</span></code> → <code class="docutils literal notranslate"><span class="pre">OpLoad</span></code></p></li>
<li><p>Calls: <code class="docutils literal notranslate"><span class="pre">call</span></code> → <code class="docutils literal notranslate"><span class="pre">OpFunctionCall</span></code></p></li>
</ul>
<p>SPIR-V defines special built-in types and operations that do not have
corresponding equivalents in LLVM IR. E.g.</p>
<ul class="simple">
<li><p>Type: ??? → <code class="docutils literal notranslate"><span class="pre">OpTypeEvent</span></code></p></li>
<li><p>Operation: ??? → <code class="docutils literal notranslate"><span class="pre">OpGroupAsyncCopy</span></code></p></li>
</ul>
<p>Translation from LLVM IR to SPIR-V for special types is also supported, but
such LLVM IR must comply to some special requirements. Unfortunately, there is
no canonical form of special built-in types and operations in LLVM IR, moreover
we can’t re-use existing representation generated by OpenCL C front-end
compiler. For instance, here is how <code class="docutils literal notranslate"><span class="pre">OpGroupAsyncCopy</span></code> operation looks in LLVM
IR produced by OpenCL C front-end compiler.</p>
<div class="highlight-LLVM notranslate"><div class="highlight"><pre><span></span><span class="vg">@_Z21async_work_group_copyPU3AS3fPU3AS1Kfjj</span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="k">addrspace</span><span class="p">(</span><span class="m">3</span><span class="p">)*,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="k">addrspace</span><span class="p">(</span><span class="m">1</span><span class="p">)*,</span><span class="w"> </span><span class="kt">i32</span><span class="p">,</span><span class="w"> </span><span class="kt">i32</span><span class="p">)</span>
</pre></div>
</div>
<p>It’s a regular function, which can conflict with user code produced from C++
source.</p>
<p>DPC++ compiler uses modified solution developed for OpenCL C++ compiler
prototype:</p>
<ul class="simple">
<li><p>Compiler: https://github.com/KhronosGroup/SPIR/tree/spirv-1.1</p></li>
<li><p>Headers: https://github.com/KhronosGroup/libclcxx</p></li>
</ul>
<p>Our solution re-uses OpenCL data types like sampler, event, image types, etc,
but we use different spelling to avoid potential conflicts with C++ code.
Spelling convention for the OpenCL types enabled in SYCL mode is:</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="n">__ocl_</span><span class="o">&lt;</span><span class="n">OpenCL_type_name</span><span class="o">&gt;</span><span class="w"> </span><span class="c1">// e.g. __ocl_sampler_t, __ocl_event_t</span>
</pre></div>
</div>
<p>Operations using OpenCL types use special naming convention described in this
<a class="reference external" href="https://github.com/KhronosGroup/SPIRV-LLVM-Translator/blob/master/docs/SPIRVRepresentationInLLVM.rst">document</a>.
This solution allows us avoid SYCL specialization in SPIR-V translator and
leverage clang infrastructure developed for OpenCL types.</p>
<p>SPIR-V operations that do not have LLVM equivalents are <strong>declared</strong>
(but not defined) in the headers and satisfy following requirements:</p>
<ul class="simple">
<li><p>the operation is expressed in C++ as <code class="docutils literal notranslate"><span class="pre">extern</span></code> function not throwing C++
exceptions</p></li>
<li><p>the operation must not have the actual definition in C++ program</p></li>
</ul>
<p>For example, the following C++ code is successfully recognized and translated
into SPIR-V operation <code class="docutils literal notranslate"><span class="pre">OpGroupAsyncCopy</span></code>:</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">dataT</span><span class="o">&gt;</span>
<span class="k">extern</span><span class="w"> </span><span class="n">__ocl_event_t</span>
<span class="n">__spirv_OpGroupAsyncCopy</span><span class="p">(</span><span class="kt">int32_t</span><span class="w"> </span><span class="n">Scope</span><span class="p">,</span><span class="w"> </span><span class="n">__local</span><span class="w"> </span><span class="n">dataT</span><span class="w"> </span><span class="o">*</span><span class="n">Dest</span><span class="p">,</span>
<span class="w">                         </span><span class="n">__global</span><span class="w"> </span><span class="n">dataT</span><span class="w"> </span><span class="o">*</span><span class="n">Src</span><span class="p">,</span><span class="w"> </span><span class="kt">size_t</span><span class="w"> </span><span class="n">NumElements</span><span class="p">,</span>
<span class="w">                         </span><span class="kt">size_t</span><span class="w"> </span><span class="n">Stride</span><span class="p">,</span><span class="w"> </span><span class="n">__ocl_event_t</span><span class="w"> </span><span class="n">E</span><span class="p">)</span><span class="w"> </span><span class="k">noexcept</span><span class="p">;</span>

<span class="n">__ocl_event_t</span><span class="w"> </span><span class="n">e</span><span class="w"> </span><span class="o">=</span>
<span class="w">  </span><span class="n">__spirv_OpGroupAsyncCopy</span><span class="p">(</span><span class="n">cl</span><span class="o">::</span><span class="n">__spirv</span><span class="o">::</span><span class="n">Scope</span><span class="o">::</span><span class="n">Workgroup</span><span class="p">,</span>
<span class="w">                           </span><span class="n">dst</span><span class="p">,</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="n">numElements</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">E</span><span class="p">);</span>
</pre></div>
</div>
<section id="some-details-and-agreements-on-using-spir-v-special-types-and-operations">
<h4>Some details and agreements on using SPIR-V special types and operations<a class="headerlink" href="#some-details-and-agreements-on-using-spir-v-special-types-and-operations" title="Link to this heading">¶</a></h4>
<p>The SPIR-V specific C++ enumerators and classes are declared in the file:
<code class="docutils literal notranslate"><span class="pre">sycl/include/CL/__spirv/spirv_types.hpp</span></code>.</p>
<p>The SPIR-V specific C++ function declarations are in the file:
<code class="docutils literal notranslate"><span class="pre">sycl/include/CL/__spirv/spirv_ops.hpp</span></code>.</p>
<p>The SPIR-V specific functions are implemented in for the SYCL host device here:
<code class="docutils literal notranslate"><span class="pre">sycl/source/spirv_ops.cpp</span></code>.</p>
</section>
</section>
<section id="address-spaces-handling">
<h3>Address spaces handling<a class="headerlink" href="#address-spaces-handling" title="Link to this heading">¶</a></h3>
<p>SYCL specification uses C++ classes to represent pointers to disjoint memory
regions on an accelerator to enable compilation with standard C++ toolchain and
SYCL compiler toolchain.</p>
<p>For instance:</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// check that SYCL mode is ON and we can use non-standard decorations</span>
<span class="cp">#if defined(__SYCL_DEVICE_ONLY__)</span>
<span class="c1">// GPU/accelerator implementation</span>
<span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">T</span><span class="p">,</span><span class="w"> </span><span class="n">address_space</span><span class="w"> </span><span class="n">AS</span><span class="o">&gt;</span><span class="w"> </span><span class="k">class</span><span class="w"> </span><span class="nc">multi_ptr</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">// DecoratedType applies corresponding address space attribute to the type T</span>
<span class="w">  </span><span class="c1">// DecoratedType&lt;T, global_space&gt;::type == &quot;__attribute__((opencl_global)) T&quot;</span>
<span class="w">  </span><span class="c1">// See sycl/include/sycl/access/access.hpp for more details</span>
<span class="w">  </span><span class="k">using</span><span class="w"> </span><span class="n">pointer_t</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">typename</span><span class="w"> </span><span class="nc">DecoratedType</span><span class="o">&lt;</span><span class="n">T</span><span class="p">,</span><span class="w"> </span><span class="n">AS</span><span class="o">&gt;::</span><span class="n">type</span><span class="w"> </span><span class="o">*</span><span class="p">;</span>

<span class="w">  </span><span class="n">pointer_t</span><span class="w"> </span><span class="n">m_Pointer</span><span class="p">;</span>
<span class="w">  </span><span class="k">public</span><span class="o">:</span>
<span class="w">  </span><span class="n">pointer_t</span><span class="w"> </span><span class="n">get</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">m_Pointer</span><span class="p">;</span><span class="w"> </span><span class="p">}</span>
<span class="w">  </span><span class="n">T</span><span class="o">&amp;</span><span class="w"> </span><span class="k">operator</span><span class="o">*</span><span class="w"> </span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="o">*</span><span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="n">T</span><span class="o">*&gt;</span><span class="p">(</span><span class="n">m_Pointer</span><span class="p">);</span><span class="w"> </span><span class="p">}</span>
<span class="p">}</span>
<span class="cp">#else</span>
<span class="c1">// CPU/host implementation</span>
<span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">T</span><span class="p">,</span><span class="w"> </span><span class="n">address_space</span><span class="w"> </span><span class="n">AS</span><span class="o">&gt;</span><span class="w"> </span><span class="k">class</span><span class="w"> </span><span class="nc">multi_ptr</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">T</span><span class="w"> </span><span class="o">*</span><span class="n">m_Pointer</span><span class="p">;</span><span class="w"> </span><span class="c1">// regular undecorated pointer</span>
<span class="w">  </span><span class="k">public</span><span class="o">:</span>
<span class="w">  </span><span class="n">T</span><span class="w"> </span><span class="o">*</span><span class="n">get</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">m_Pointer</span><span class="p">;</span><span class="w"> </span><span class="p">}</span>
<span class="w">  </span><span class="n">T</span><span class="o">&amp;</span><span class="w"> </span><span class="k">operator</span><span class="o">*</span><span class="w"> </span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="o">*</span><span class="n">m_Pointer</span><span class="p">;</span><span class="w"> </span><span class="p">}</span>
<span class="p">}</span>
<span class="cp">#endif</span>
</pre></div>
</div>
<p>Depending on the compiler mode <code class="docutils literal notranslate"><span class="pre">multi_ptr</span></code> will either decorate internal data
with address space attribute or not.</p>
<p>The main address space semantic difference of SYCL mode from OpenCL is that
SYCL doesn’t assign OpenCL generic address space to a declaration’s type without
explicit address space attribute. Similar to other single-source C++-based GPU
programming modes like OpenMP/CUDA/HIP, SYCL uses clang’s “default” address
space for types with no address space attributes. During the lowering to LLVM
IR, the default address space is mapped to the SPIR generic address space.
Declarations are assigned to the relevant memory region depending on their
declaration context and pointers to them are cast to generic. This design has
two important features: keeps the type system consistent with C++ on one hand
and enable tools for emitting device code aligned with SPIR memory model (and
other GPU targets).</p>
<p>So inside a function, this variable declaration:</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="w"> </span><span class="n">var</span><span class="p">;</span>
</pre></div>
</div>
<p>DPC++ turn into</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="n">VarDecl</span><span class="w">  </span><span class="n">var</span><span class="w"> </span><span class="err">&#39;</span><span class="kt">int</span><span class="err">&#39;</span>
</pre></div>
</div>
<p>OpenCL compiler turn into</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="n">VarDecl</span><span class="w">  </span><span class="n">var</span><span class="w"> </span><span class="err">&#39;</span><span class="n">__private</span><span class="w"> </span><span class="kt">int</span><span class="err">&#39;</span>
</pre></div>
</div>
<p>Changing variable type has massive and destructive effect in C++. For instance
this does not compile in C++ for OpenCL mode:</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="k">template</span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">T1</span><span class="p">,</span><span class="w"> </span><span class="k">typename</span><span class="w"> </span><span class="nc">T2</span><span class="o">&gt;</span>
<span class="k">struct</span><span class="w"> </span><span class="nc">is_same</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">static</span><span class="w"> </span><span class="k">constexpr</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">value</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">};</span>

<span class="k">template</span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">T</span><span class="o">&gt;</span>
<span class="k">struct</span><span class="w"> </span><span class="nc">is_same</span><span class="o">&lt;</span><span class="n">T</span><span class="p">,</span><span class="w"> </span><span class="n">T</span><span class="o">&gt;</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">static</span><span class="w"> </span><span class="k">constexpr</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">value</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="p">};</span>

<span class="kt">void</span><span class="w"> </span><span class="nf">foo</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">p</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">static_assert</span><span class="p">(</span><span class="n">is_same</span><span class="o">&lt;</span><span class="k">decltype</span><span class="p">(</span><span class="n">p</span><span class="p">),</span><span class="w"> </span><span class="kt">int</span><span class="o">&gt;::</span><span class="n">value</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;int is not an int?&quot;</span><span class="p">);</span><span class="w"> </span><span class="c1">// Fails: p is &#39;__private int&#39; != &#39;int&#39;</span>
<span class="w">    </span><span class="k">static_assert</span><span class="p">(</span><span class="n">is_same</span><span class="o">&lt;</span><span class="k">decltype</span><span class="p">(</span><span class="o">&amp;</span><span class="n">p</span><span class="p">),</span><span class="w"> </span><span class="kt">int</span><span class="o">*&gt;::</span><span class="n">value</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;int* is not an int*?&quot;</span><span class="p">);</span><span class="w">  </span><span class="c1">// Fails: p is &#39;__private int*&#39; != &#39;__generic int*&#39;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>To utilize existing clang’s functionality, we re-use following OpenCL address
space attributes in SYCL mode:</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Address space attribute</p></th>
<th class="head"><p>SYCL address_space enumeration</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">__attribute__((opencl_global))</span></code></p></td>
<td><p>global_space, constant_space</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">__attribute__((opencl_global_host))</span></code></p></td>
<td><p>ext_intel_global_host_space</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">__attribute__((opencl_global_device))</span></code></p></td>
<td><p>ext_intel_global_device_space</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">__attribute__((opencl_local))</span></code></p></td>
<td><p>local_space</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">__attribute__((opencl_private))</span></code></p></td>
<td><p>private_space</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">__attribute__((opencl_constant))</span></code></p></td>
<td><p>N/A</p></td>
</tr>
</tbody>
</table>
<blockquote>
<div><p><strong>NOTE</strong>: although SYCL device compiler supports
<code class="docutils literal notranslate"><span class="pre">__attribute__((opencl_constant))</span></code>, the use of this attribute is limited within
SYCL implementation. An OpenCL constant pointer can not be casted to a pointer
with any other address space (including default).</p>
</div></blockquote>
</section>
<section id="compiler-runtime-interface">
<h3>Compiler/Runtime interface<a class="headerlink" href="#compiler-runtime-interface" title="Link to this heading">¶</a></h3>
</section>
</section>
<section id="dpc-runtime-architecture">
<h2>DPC++ Runtime architecture<a class="headerlink" href="#dpc-runtime-architecture" title="Link to this heading">¶</a></h2>
<p><em>TBD</em></p>
</section>
<section id="dpc-language-extensions-to-sycl">
<h2>DPC++ Language extensions to SYCL<a class="headerlink" href="#dpc-language-extensions-to-sycl" title="Link to this heading">¶</a></h2>
<p>List of language extensions can be found at <a class="reference external" href="https://github.com/intel/llvm/blob/sycl/doc/extensions/">extensions</a></p>
</section>
</section>


      </div>
      <div class="bottomnav" role="navigation" aria-label="bottom navigation">
      
        <p>
        «&#160;&#160;<a href="../syclgraph/SYCLGraphUsageGuide.html">SYCL Graph Usage Guide and Examples</a>
        &#160;&#160;::&#160;&#160;
        <a class="uplink" href="../index.html">Contents</a>
        &#160;&#160;::&#160;&#160;
        <a href="KernelParameterPassing.html">SYCL Kernel Parameter Handling and Array Support</a>&#160;&#160;»
        </p>

      </div>

    <div class="footer" role="contentinfo">
    &#169; Copyright 2024, Intel Corporation.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.3.7.
    </div>
  </body>
</html>