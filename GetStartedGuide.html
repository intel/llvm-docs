<!DOCTYPE html>

<html lang="en" data-content_root="./">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Getting Started with oneAPI DPC++ &#8212; oneAPI DPC++ Compiler  documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=649a27d8" />
    <link rel="stylesheet" type="text/css" href="_static/haiku.css?v=dfa0e015" />
    <script src="_static/documentation_options.js?v=5929fcd5"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Users Manual" href="UsersManual.html" />
    <link rel="prev" title="DPC++ Documentation" href="index.html" /> 
  </head><body>
      <div class="header" role="banner"><h1 class="heading"><a href="index.html">
          <span>oneAPI DPC++ Compiler  documentation</span></a></h1>
        <h2 class="heading"><span>Getting Started with oneAPI DPC++</span></h2>
      </div>
      <div class="topnav" role="navigation" aria-label="top navigation">
      
        <p>
        «&#160;&#160;<a href="index.html">DPC++ Documentation</a>
        &#160;&#160;::&#160;&#160;
        <a class="uplink" href="index.html">Contents</a>
        &#160;&#160;::&#160;&#160;
        <a href="UsersManual.html">Users Manual</a>&#160;&#160;»
        </p>

      </div>
      <div class="content" role="main">
        
        
  <section id="getting-started-with-oneapi-dpc">
<h1>Getting Started with oneAPI DPC++<a class="headerlink" href="#getting-started-with-oneapi-dpc" title="Link to this heading">¶</a></h1>
<p>The DPC++ Compiler compiles C++ and SYCL* source files with code for both CPU
and a wide range of compute accelerators such as GPU and FPGA.</p>
<section id="table-of-contents">
<h2>Table of contents<a class="headerlink" href="#table-of-contents" title="Link to this heading">¶</a></h2>
<ul class="simple">
<li><p><a class="reference internal" href="#prerequisites">Prerequisites</a></p>
<ul>
<li><p><a class="reference internal" href="#create-dpc-workspace">Create DPC++ workspace</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#build-dpc-toolchain">Build DPC++ toolchain</a></p>
<ul>
<li><p><a class="reference internal" href="#build-dpc-toolchain-with-libc-library">Build DPC++ toolchain with libc++ library</a></p></li>
<li><p><a class="reference internal" href="#build-dpc-toolchain-with-support-for-nvidia-cuda">Build DPC++ toolchain with support for NVIDIA CUDA</a></p></li>
<li><p><a class="reference internal" href="#build-dpc-toolchain-with-support-for-hip-amd">Build DPC++ toolchain with support for HIP AMD</a></p></li>
<li><p><a class="reference internal" href="#build-dpc-toolchain-with-support-for-hip-nvidia">Build DPC++ toolchain with support for HIP NVIDIA</a></p></li>
<li><p><a class="reference internal" href="#build-dpc-toolchain-with-support-for-runtime-kernel-fusion-and-jit-compilation">Build DPC++ toolchain with support for runtime kernel fusion and JIT compilation</a></p></li>
<li><p><a class="reference internal" href="#build-dpc-toolchain-with-a-custom-unified-runtime">Build DPC++ toolchain with a custom Unified Runtime</a></p></li>
<li><p><a class="reference internal" href="#build-doxygen-documentation">Build Doxygen documentation</a></p></li>
<li><p><a class="reference internal" href="#deployment">Deployment</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#use-dpc-toolchain">Use DPC++ toolchain</a></p>
<ul>
<li><p><a class="reference internal" href="#install-low-level-runtime">Install low level runtime</a></p></li>
<li><p><a class="reference internal" href="#obtain-prerequisites-for-ahead-of-time-aot-compilation">Obtain prerequisites for ahead of time (AOT) compilation</a></p>
<ul>
<li><p><a class="reference internal" href="#gpu">GPU</a></p></li>
<li><p><a class="reference internal" href="#cpu">CPU</a></p></li>
<li><p><a class="reference internal" href="#accelerator">Accelerator</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#test-dpc-toolchain">Test DPC++ toolchain</a></p>
<ul>
<li><p><a class="reference internal" href="#run-in-tree-lit-tests">Run in-tree LIT tests</a></p></li>
<li><p><a class="reference internal" href="#run-dpc-e2e-tests">Run DPC++ E2E tests</a></p></li>
<li><p><a class="reference internal" href="#run-khronos-sycl-conformance-test-suite-optional">Run Khronos* SYCL* conformance test suite (optional)</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#run-simple-dpc-application">Run simple DPC++ application</a></p>
<ul>
<li><p><a class="reference internal" href="#aot-target-architectures">AOT Target architectures</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#build-dpc-application-with-cmake">Build DPC++ application with CMake</a></p></li>
<li><p><a class="reference internal" href="#code-the-program-for-a-specific-gpu">Code the program for a specific GPU</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#c-standard">C++ standard</a></p></li>
<li><p><a class="reference internal" href="#known-issues-and-limitations">Known Issues and Limitations</a></p>
<ul>
<li><p><a class="reference internal" href="#cuda-back-end-limitations">CUDA back-end limitations</a></p></li>
<li><p><a class="reference internal" href="#hip-back-end-limitations">HIP back-end limitations</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#find-more">Find More</a></p></li>
</ul>
</section>
<section id="prerequisites">
<h2>Prerequisites<a class="headerlink" href="#prerequisites" title="Link to this heading">¶</a></h2>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">git</span></code> - <a class="reference external" href="https://git-scm.com/downloads">Download</a></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cmake</span></code> version 3.20 or later - <a class="reference external" href="http://www.cmake.org/download/">Download</a></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">python</span></code> - <a class="reference external" href="https://www.python.org/downloads/">Download</a></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ninja</span></code> -
<a class="reference external" href="https://github.com/ninja-build/ninja/wiki/Pre-built-Ninja-packages">Download</a></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">hwloc</span></code> version 2.3 or later (Linux only)</p>
<ul>
<li><p>libhwloc-dev or hwloc-devel package on linux</p></li>
</ul>
</li>
<li><p>C++ compiler</p>
<ul>
<li><p>See LLVM’s <a class="reference external" href="https://github.com/intel/llvm/blob/sycl/llvm/docs/GettingStarted.rst#host-c-toolchain-both-compiler-and-standard-library">host compiler toolchain requirements</a></p></li>
</ul>
</li>
</ul>
<p>Alternatively, you can use a Docker image that has everything you need for
building pre-installed:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker<span class="w"> </span>run<span class="w"> </span>--name<span class="w"> </span>sycl_build<span class="w"> </span>-it<span class="w"> </span>-v<span class="w"> </span>/local/workspace/dir/:/src<span class="w"> </span>ghcr.io/intel/llvm/ubuntu2204_build<span class="w"> </span>/bin/bash
</pre></div>
</div>
<p>This command will start a terminal session, from which you can proceed with the
instructions below. See <a class="reference internal" href="developer/DockerBKMs.html"><span class="std std-doc">Docker BKMs</span></a> for more info on
Docker commands.</p>
<section id="create-dpc-workspace">
<h3>Create DPC++ workspace<a class="headerlink" href="#create-dpc-workspace" title="Link to this heading">¶</a></h3>
<p>Throughout this document <code class="docutils literal notranslate"><span class="pre">DPCPP_HOME</span></code> denotes the path to the local directory
created as DPC++ workspace. It might be useful to create an environment variable
with the same name.</p>
<p><strong>Linux</strong>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">DPCPP_HOME</span><span class="o">=</span>~/sycl_workspace
mkdir<span class="w"> </span><span class="nv">$DPCPP_HOME</span>
<span class="nb">cd</span><span class="w"> </span><span class="nv">$DPCPP_HOME</span>

git<span class="w"> </span>clone<span class="w"> </span>https://github.com/intel/llvm<span class="w"> </span>-b<span class="w"> </span>sycl
</pre></div>
</div>
<p><strong>Windows (64-bit)</strong>:</p>
<p>Open a developer command prompt using one of two methods:</p>
<ul class="simple">
<li><p>Click start menu and search for “<strong>x64</strong> Native Tools Command Prompt for VS
XXXX”, where XXXX is a version of installed Visual Studio.</p></li>
<li><p>Ctrl-R, write “cmd”, click enter, then run
<code class="docutils literal notranslate"><span class="pre">&quot;C:\Program</span> <span class="pre">Files</span> <span class="pre">(x86)\Microsoft</span> <span class="pre">Visual</span> <span class="pre">Studio\2017\Community\VC\Auxiliary\Build\vcvarsall.bat&quot;</span> <span class="pre">x64</span></code></p></li>
</ul>
<div class="highlight-bat notranslate"><div class="highlight"><pre><span></span><span class="k">set</span> <span class="nv">DPCPP_HOME</span><span class="p">=</span><span class="nv">%USERPROFILE%</span>\sycl_workspace
<span class="k">mkdir</span> <span class="nv">%DPCPP_HOME%</span>
<span class="k">cd</span> <span class="nv">%DPCPP_HOME%</span>

git clone --config core.autocrlf=false https://github.com/intel/llvm -b sycl
</pre></div>
</div>
</section>
</section>
<section id="build-dpc-toolchain">
<h2>Build DPC++ toolchain<a class="headerlink" href="#build-dpc-toolchain" title="Link to this heading">¶</a></h2>
<p>The easiest way to get started is to use the buildbot
<a class="reference download internal" download="" href="_downloads/e1ec63659e68e536396ca53a51bb428d/configure.py"><span class="xref download myst">configure</span></a> and
<a class="reference download internal" download="" href="_downloads/c1a9e03c6baa258f9c4dc131aeeee13d/compile.py"><span class="xref download myst">compile</span></a> scripts.</p>
<p>In case you want to configure CMake manually the up-to-date reference for
variables is in these files.</p>
<p><strong>Linux</strong>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span><span class="nv">$DPCPP_HOME</span>/llvm/buildbot/configure.py
python<span class="w"> </span><span class="nv">$DPCPP_HOME</span>/llvm/buildbot/compile.py
</pre></div>
</div>
<p><strong>Windows (64-bit)</strong>:</p>
<div class="highlight-bat notranslate"><div class="highlight"><pre><span></span>python <span class="nv">%DPCPP_HOME%</span>\llvm\buildbot\configure.py
python <span class="nv">%DPCPP_HOME%</span>\llvm\buildbot\compile.py
</pre></div>
</div>
<p>You can use the following flags with <code class="docutils literal notranslate"><span class="pre">configure.py</span></code> (full list of available
flags can be found by launching the script with <code class="docutils literal notranslate"><span class="pre">--help</span></code>):</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">--werror</span></code> -&gt; treat warnings as errors when compiling LLVM</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--cuda</span></code> -&gt; use the cuda backend (see
<a class="reference internal" href="#build-dpc-toolchain-with-support-for-nvidia-cuda">Nvidia CUDA</a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--hip</span></code> -&gt; use the HIP backend (see
<a class="reference internal" href="#build-dpc-toolchain-with-support-for-hip-amd">HIP</a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--hip-platform</span></code> -&gt; select the platform used by the hip backend, <code class="docutils literal notranslate"><span class="pre">AMD</span></code> or
<code class="docutils literal notranslate"><span class="pre">NVIDIA</span></code> (see <a class="reference internal" href="#build-dpc-toolchain-with-support-for-hip-amd">HIP AMD</a> or see
<a class="reference internal" href="#build-dpc-toolchain-with-support-for-hip-nvidia">HIP NVIDIA</a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--enable-all-llvm-targets</span></code> -&gt; build compiler (but not a runtime) with all
supported targets</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--shared-libs</span></code> -&gt; Build shared libraries</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-t</span></code> -&gt; Build type (Debug or Release)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-o</span></code> -&gt; Path to build directory</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--cmake-gen</span></code> -&gt; Set build system type (e.g. <code class="docutils literal notranslate"><span class="pre">--cmake-gen</span> <span class="pre">&quot;Unix</span> <span class="pre">Makefiles&quot;</span></code>)</p></li>
</ul>
<p>You can use the following flags with <code class="docutils literal notranslate"><span class="pre">compile.py</span></code> (full list of available flags
can be found by launching the script with <code class="docutils literal notranslate"><span class="pre">--help</span></code>):</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">-o</span></code> -&gt; Path to build directory</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-t</span></code>, <code class="docutils literal notranslate"><span class="pre">--build-target</span></code> -&gt; Build target (e.g., <code class="docutils literal notranslate"><span class="pre">clang</span></code> or <code class="docutils literal notranslate"><span class="pre">llvm-spirv</span></code>).
Default is <code class="docutils literal notranslate"><span class="pre">deploy-sycl-toolchain</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-j</span></code>, <code class="docutils literal notranslate"><span class="pre">--build-parallelism</span></code> -&gt; Number of threads to use for compilation</p></li>
</ul>
<p><strong>Please note</strong> that no data about flags is being shared between <code class="docutils literal notranslate"><span class="pre">configure.py</span></code>
and <code class="docutils literal notranslate"><span class="pre">compile.py</span></code> scripts, which means that if you configured your build to be
placed in non-default directory using <code class="docutils literal notranslate"><span class="pre">-o</span></code> flag, you must also specify this flag
and the same path in <code class="docutils literal notranslate"><span class="pre">compile.py</span></code> options. This allows you, for example, to
configure several different builds and then build just one of them which is
needed at the moment.</p>
<section id="build-dpc-toolchain-with-libc-library">
<h3>Build DPC++ toolchain with libc++ library<a class="headerlink" href="#build-dpc-toolchain-with-libc-library" title="Link to this heading">¶</a></h3>
<p>There is experimental support for building and linking DPC++ runtime with libc++
library instead of libstdc++. To enable it the following CMake options should be
used.</p>
<p><strong>Linux</strong>:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>-DSYCL_USE_LIBCXX<span class="o">=</span>ON<span class="w"> </span><span class="se">\</span>
-DSYCL_LIBCXX_INCLUDE_PATH<span class="o">=</span>&lt;path<span class="w"> </span>to<span class="w"> </span>libc++<span class="w"> </span>headers&gt;<span class="w"> </span><span class="se">\</span>
-DSYCL_LIBCXX_LIBRARY_PATH<span class="o">=</span>&lt;path<span class="w"> </span>to<span class="w"> </span>libc++<span class="w"> </span>and<span class="w"> </span>libc++abi<span class="w"> </span>libraries&gt;
</pre></div>
</div>
<p>You can also use configure script to enable:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>%DPCPP_HOME%<span class="se">\l</span>lvm<span class="se">\b</span>uildbot<span class="se">\c</span>onfigure.py<span class="w"> </span>--use-libcxx<span class="w"> </span><span class="se">\</span>
--libcxx-include<span class="w"> </span>&lt;path<span class="w"> </span>to<span class="w"> </span>libc++<span class="w"> </span>headers&gt;<span class="w"> </span><span class="se">\</span>
--libcxx-library<span class="w"> </span>&lt;path<span class="w"> </span>to<span class="w"> </span>libc++<span class="w"> </span>and<span class="w"> </span>libc++<span class="w"> </span>abi<span class="w"> </span>libraries&gt;
python<span class="w"> </span>%DPCPP_HOME%<span class="se">\l</span>lvm<span class="se">\b</span>uildbot<span class="se">\c</span>ompile.py
</pre></div>
</div>
</section>
<section id="build-dpc-toolchain-with-support-for-nvidia-cuda">
<h3>Build DPC++ toolchain with support for NVIDIA CUDA<a class="headerlink" href="#build-dpc-toolchain-with-support-for-nvidia-cuda" title="Link to this heading">¶</a></h3>
<p>To enable support for CUDA devices, follow the instructions for the Linux or
Windows DPC++ toolchain, but add the <code class="docutils literal notranslate"><span class="pre">--cuda</span></code> flag to <code class="docutils literal notranslate"><span class="pre">configure.py</span></code>. Note, the
CUDA backend has Windows support; Windows Subsystem for Linux (WSL) is not
needed to build and run the CUDA backend.</p>
<p>Refer to
<a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html">NVIDIA CUDA Installation Guide for Linux</a>
or
<a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/index.html">NVIDIA CUDA Installation Guide for Windows</a>
for CUDA toolkit installation instructions.</p>
<p>Errors may occur if DPC++ is built with a toolkit version which is higher than
the CUDA driver version. In order to check that the CUDA driver and toolkits
match, use the CUDA executable <code class="docutils literal notranslate"><span class="pre">deviceQuery</span></code> which is usually found in
<code class="docutils literal notranslate"><span class="pre">$CUDA_INSTALL_DIR/cuda/extras/demo_suite/deviceQuery</span></code>.</p>
<p><strong><em>NOTE:</em></strong> An installation of at least
<a class="reference external" href="https://developer.nvidia.com/cuda-downloads">CUDA 11.6</a> is recommended because
there is a known issue with some math built-ins when using -O1/O2/O3
Optimization options for CUDA toolkits prior to 11.6 (This is due to a bug in
earlier versions of the CUDA toolkit: see
<a class="reference external" href="https://forums.developer.nvidia.com/t/libdevice-functions-causing-ptxas-segfault/193352">this issue</a>).</p>
<p><strong><em>NOTE:</em></strong> CUDA toolkit versions earlier than 11.0 are not regularly tested,
but should work for appropriate devices. Note that for example some oneapi
extensions that require sm_80 and later architectures also require at least CUDA
11.0.</p>
<p>The CUDA backend should work on Windows or Linux operating systems with any GPU
with compute capability (SM version) sm_50 or above. The default SM version for
the NVIDIA CUDA backend is sm_50. Users of sm_3X devices can attempt to specify
the target architecture <a class="reference internal" href="#aot-target-architectures">ahead of time</a>, provided
that they use a 11.X  or earlier CUDA toolkit version, but some features may not be
supported. The CUDA backend has been tested with different Ubuntu Linux
distributions and a selection of supported CUDA toolkit versions and GPUs.
The backend is tested by a relevant device/toolkit prior to a ONEAPI plugin release.
Go to the plugin release
<a class="reference external" href="https://developer.codeplay.com/products/oneapi/nvidia/">pages</a> for further
details.</p>
<p><strong>Non-standard CUDA location</strong>:</p>
<p>If the CUDA toolkit is installed in a non-default location on your system, two
considerations must be made.</p>
<p>Firstly, <strong>do not</strong> add the toolkit to your standard environment variables
(<code class="docutils literal notranslate"><span class="pre">PATH</span></code>, <code class="docutils literal notranslate"><span class="pre">LD_LIBRARY_PATH</span></code>), as to do so will create conflicts with OpenCL
headers.</p>
<p>Secondly, set the <code class="docutils literal notranslate"><span class="pre">CUDA_LIB_PATH</span></code> environment variable and pass the CMake
variable <code class="docutils literal notranslate"><span class="pre">CUDA_TOOLKIT_ROOT_DIR</span></code> as follows:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_LIB_PATH</span><span class="o">=</span>/path/to/cuda/toolkit/lib64/stubs<span class="w"> </span><span class="nv">CC</span><span class="o">=</span>gcc<span class="w"> </span><span class="nv">CXX</span><span class="o">=</span>g++<span class="w"> </span>python<span class="w"> </span><span class="nv">$DPCPP_HOME</span>/llvm/buildbot/configure.py<span class="w"> </span>--cuda<span class="w"> </span>--cmake-opt<span class="o">=</span><span class="s2">&quot;-DCUDA_TOOLKIT_ROOT_DIR=/path/to/cuda/toolkit&quot;</span>

<span class="nv">CUDA_LIB_PATH</span><span class="o">=</span>/path/to/cuda/toolkit/lib64/stubs<span class="w"> </span><span class="nv">CC</span><span class="o">=</span>gcc<span class="w"> </span><span class="nv">CXX</span><span class="o">=</span>g++<span class="w"> </span>python<span class="w"> </span><span class="nv">$DPCPP_HOME</span>/llvm/buildbot/compile.py

<span class="nv">$DPCPP_HOME</span>/llvm/build/bin/clang++<span class="w"> </span>-std<span class="o">=</span>c++17<span class="w"> </span>-O3<span class="w"> </span>-fsycl<span class="w"> </span>-fsycl-targets<span class="o">=</span>nvptx64-nvidia-cuda<span class="w"> </span>--cuda-path<span class="o">=</span>/path/to/cuda/toolkit<span class="w"> </span>*.cpp<span class="w"> </span>-o<span class="w"> </span>a.out

<span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="nv">$LD_LIBRARY_PATH</span>:<span class="nv">$DPCPP_HOME</span>/llvm/build/lib<span class="w"> </span>./a.out
</pre></div>
</div>
</section>
<section id="build-dpc-toolchain-with-support-for-hip-amd">
<h3>Build DPC++ toolchain with support for HIP AMD<a class="headerlink" href="#build-dpc-toolchain-with-support-for-hip-amd" title="Link to this heading">¶</a></h3>
<p>There is beta support for oneAPI DPC++ for HIP on AMD devices. It is not feature
complete and it still contains known and unknown bugs. Currently it has only
been tried on Linux, with ROCm 4.2.0, 4.3.0, 4.5.2, 5.3.0, and 5.4.3, using the
AMD Radeon Pro W6800 (gtx1030), MI50 (gfx906), MI100 (gfx908) and MI250x
(gfx90a) devices. The backend is tested by a relevant device/toolkit prior to a
oneAPI plugin release. Go to the plugin release
<a class="reference external" href="https://developer.codeplay.com/products/oneapi/amd">pages</a> for further details.</p>
<p>To enable support for HIP devices, follow the instructions for the Linux DPC++
toolchain, but add the <code class="docutils literal notranslate"><span class="pre">--hip</span></code> flag to <code class="docutils literal notranslate"><span class="pre">configure.py</span></code>.</p>
<p>Enabling this flag requires an installation of ROCm on the system, for
instruction on how to install this refer to
<a class="reference external" href="https://rocmdocs.amd.com/en/latest/Installation_Guide/Installation-Guide.html">AMD ROCm Installation Guide for Linux</a>.</p>
<p>The DPC++ build assumes that ROCm is installed in <code class="docutils literal notranslate"><span class="pre">/opt/rocm</span></code>, if it is
installed somewhere else, the directory must be provided through the CMake
variable <code class="docutils literal notranslate"><span class="pre">SYCL_BUILD_PI_HIP_ROCM_DIR</span></code> which can be passed using the
<code class="docutils literal notranslate"><span class="pre">--cmake-opt</span></code> option of <code class="docutils literal notranslate"><span class="pre">configure.py</span></code> as follows:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span><span class="nv">$DPCPP_HOME</span>/llvm/buildbot/configure.py<span class="w"> </span>--hip<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--cmake-opt<span class="o">=</span>-DSYCL_BUILD_PI_HIP_ROCM_DIR<span class="o">=</span>/usr/local/rocm
</pre></div>
</div>
<p>If further customization is required — for instance when the layout of
individual directories can not be inferred from <code class="docutils literal notranslate"><span class="pre">SYCL_BUILD_PI_HIP_ROCM_DIR</span></code> —
it is possible to specify the location of HIP include, HSA include and HIP
library directories, using the following CMake variables:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">SYCL_BUILD_PI_HIP_INCLUDE_DIR</span></code>,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">SYCL_BUILD_PI_HIP_HSA_INCLUDE_DIR</span></code>,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">SYCL_BUILD_PI_HIP_LIB_DIR</span></code>.
Please note that a similar customization would also be required for Unified
Runtime, see <a class="reference external" href="https://github.com/oneapi-src/unified-runtime#cmake-standard-options">the list of options provided by its
CMake</a>
for details.</p></li>
</ul>
<p><a class="reference external" href="https://llvm.org/docs/AMDGPUUsage.html">LLD</a> is necessary for the AMDGPU
compilation chain. The AMDGPU backend generates a standard ELF relocatable code
object that can be linked by lld to produce a standard ELF shared code object
which can be loaded and executed on an AMDGPU target. The LLD project is enabled
by default when configuring for HIP. For more details on building LLD refer to
<a class="reference external" href="https://lld.llvm.org/">LLD Build Guide</a>.</p>
</section>
<section id="build-dpc-toolchain-with-support-for-hip-nvidia">
<h3>Build DPC++ toolchain with support for HIP NVIDIA<a class="headerlink" href="#build-dpc-toolchain-with-support-for-hip-nvidia" title="Link to this heading">¶</a></h3>
<p>There is experimental support for oneAPI DPC++ for HIP on Nvidia devices.
There is no continuous integration for this and there are no guarantees for
supported platforms or configurations.</p>
<p>This is a compatibility feature and the
<a class="reference internal" href="#build-dpc-toolchain-with-support-for-nvidia-cuda">CUDA backend</a>
should be preferred to run on NVIDIA GPUs.</p>
<p>To enable support for HIP NVIDIA devices, follow the instructions for the Linux
DPC++ toolchain, but add the <code class="docutils literal notranslate"><span class="pre">--hip</span></code> and <code class="docutils literal notranslate"><span class="pre">--hip-platform</span> <span class="pre">NVIDIA</span></code> flags to
<code class="docutils literal notranslate"><span class="pre">configure.py</span></code>.</p>
<p>Enabling this flag requires HIP to be installed, more specifically
<a class="reference external" href="https://rocmdocs.amd.com/en/latest/Installation_Guide/HIP-Installation.html#nvidia-platform">HIP NVCC</a>,
as well as the CUDA Runtime API to be installed, see
<a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html">NVIDIA CUDA Installation Guide for Linux</a>.</p>
<p>Currently, this has only been tried on Linux, with ROCm 4.2.0 or 4.3.0, with
CUDA 11, and using a GeForce 1060 device.</p>
</section>
<section id="build-dpc-toolchain-with-support-for-runtime-kernel-fusion-and-jit-compilation">
<h3>Build DPC++ toolchain with support for runtime kernel fusion and JIT compilation<a class="headerlink" href="#build-dpc-toolchain-with-support-for-runtime-kernel-fusion-and-jit-compilation" title="Link to this heading">¶</a></h3>
<p>Support for the experimental SYCL extension for user-driven kernel fusion at
runtime is enabled by default. The same mechanism is used to allow JIT
compilation of AMD and Nvidia kernels.</p>
<p>To disable support for these features, follow the instructions for the Linux
DPC++ toolchain, but add the <code class="docutils literal notranslate"><span class="pre">--disable-jit</span></code> flag.</p>
<p>Both kernel fusion and JIT compilation of AMD and Nvidia kernels are currently
not yet supported on the Windows platform.</p>
</section>
<section id="build-doxygen-documentation">
<h3>Build Doxygen documentation<a class="headerlink" href="#build-doxygen-documentation" title="Link to this heading">¶</a></h3>
<p>Building Doxygen documentation is similar to building the product itself. First,
the following tools need to be installed:</p>
<ul class="simple">
<li><p>doxygen</p></li>
<li><p>graphviz</p></li>
<li><p>sphinx</p></li>
</ul>
<p>Then you’ll need to add the following options to your CMake configuration
command:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>-DLLVM_ENABLE_DOXYGEN<span class="o">=</span>ON
</pre></div>
</div>
<p>After CMake cache is generated, build the documentation with <code class="docutils literal notranslate"><span class="pre">doxygen-sycl</span></code>
target. It will be put to <code class="docutils literal notranslate"><span class="pre">$DPCPP_HOME/llvm/build/tools/sycl/doc/html</span></code>
directory.</p>
</section>
<section id="build-dpc-toolchain-with-a-custom-unified-runtime">
<h3>Build DPC++ toolchain with a custom Unified Runtime<a class="headerlink" href="#build-dpc-toolchain-with-a-custom-unified-runtime" title="Link to this heading">¶</a></h3>
<p>DPC++ uses the <a class="reference external" href="https://github.com/oneapi-src/unified-runtime">Unified Runtime</a>
under the hood to provide implementations of various SYCL backends. By default
the source code for the Unified Runtime will be acquired using CMake’s
<a class="reference external" href="https://cmake.org/cmake/help/latest/module/FetchContent.html">FetchCotent</a>. The
specific repository URL and revision tag used can be found in the file
<code class="docutils literal notranslate"><span class="pre">sycl/plugins/unified_runtime/CMakeLists.txt</span></code> searching for the variables
<code class="docutils literal notranslate"><span class="pre">UNIFIED_RUNTIME_REPO</span></code> and <code class="docutils literal notranslate"><span class="pre">UNIFIED_RUNTIME_TAG</span></code>.</p>
<p>In order to enable developers, a number of CMake variables are available to
control which revision of Unified Runtime should be used when building DPC++:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">SYCL_UR_OVERRIDE_FETCH_CONTENT_REPO</span></code> is a variable which can be used to
override the <code class="docutils literal notranslate"><span class="pre">UNIFIED_RUNTIME_REPO</span></code> variable used by <code class="docutils literal notranslate"><span class="pre">FetchContent</span></code> to attain
the Unified Runtime source code.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">SYCL_UR_OVERRIDE_FETCH_CONTENT_TAG</span></code> is a variable which can be used to
override the <code class="docutils literal notranslate"><span class="pre">UNIFIED_RUNTIME_TAG</span></code> variable used by <code class="docutils literal notranslate"><span class="pre">FetchContent</span></code> to attain
the Unified Runtime source code.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">SYCL_UR_USE_FETCH_CONTENT</span></code> is an option to control if CMake should use
<code class="docutils literal notranslate"><span class="pre">FetchContent</span></code> to pull in the Unified Runtime repository, it defaults to <code class="docutils literal notranslate"><span class="pre">ON</span></code>.
When set to <code class="docutils literal notranslate"><span class="pre">OFF</span></code>, <code class="docutils literal notranslate"><span class="pre">FetchContent</span></code> will not be used, instead:</p>
<ul>
<li><p>The path specified by variable <code class="docutils literal notranslate"><span class="pre">SYCL_UR_SOURCE_DIR</span></code> will be used with
<code class="docutils literal notranslate"><span class="pre">add_directory()</span></code>. This can be used to point at an adjacent directory
containing a clone of the Unified Runtime repository.</p></li>
<li><p>The path <code class="docutils literal notranslate"><span class="pre">sycl/plugins/unified_runtime/unified-runtime</span></code> will be used, if it
exists. This can be used as-if an in-tree build.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">SYCL_UR_SOURCE_DIR</span></code> is a variable used to specify the path to the Unified
Runtime repository when <code class="docutils literal notranslate"><span class="pre">SYCL_UR_USE_FETCH_CONTENT</span></code> is set of <code class="docutils literal notranslate"><span class="pre">OFF</span></code>.</p></li>
</ul>
</section>
<section id="build-dpc-libclc-with-a-custom-toolchain">
<h3>Build DPC++ libclc with a custom toolchain<a class="headerlink" href="#build-dpc-libclc-with-a-custom-toolchain" title="Link to this heading">¶</a></h3>
<p>libclc is an implementation of the OpenCL required libraries, as described in
the <a class="reference external" href="https://www.khronos.org/registry/OpenCL/specs/3.0-unified/html/OpenCL_C.html">OpenCL C specification</a>,
additionally providing definitions of SPIR-V builtins. It is built to
target-specific bitcode, that is linked against SYCL binaries. By default, the
built system uses the SYCL toolchain currently being built to create libclc
bitcode. This can be suboptimal in case of debug builds, in which case debug
tools are used to build non-debug libclc bitcode (the notion of debug builds
doesn’t really apply to libclc), resulting in very long compilation time. In
order to specify a directory containing custom toolchain users can set:
<code class="docutils literal notranslate"><span class="pre">LIBCLC_CUSTOM_LLVM_TOOLS_BINARY_DIR</span></code> variable. Care is required, as the
changes to the local SYCL tree might not be reflected in the custom location
during the build time.</p>
</section>
<section id="deployment">
<h3>Deployment<a class="headerlink" href="#deployment" title="Link to this heading">¶</a></h3>
<p>TODO: add instructions how to deploy built DPC++ toolchain.</p>
</section>
</section>
<section id="use-dpc-toolchain">
<h2>Use DPC++ toolchain<a class="headerlink" href="#use-dpc-toolchain" title="Link to this heading">¶</a></h2>
<section id="install-low-level-runtime">
<h3>Install low level runtime<a class="headerlink" href="#install-low-level-runtime" title="Link to this heading">¶</a></h3>
<p>To run DPC++ applications on OpenCL devices, OpenCL implementation(s) must be
present in the system.</p>
<p>To run DPC++ applications on Level Zero devices, Level Zero implementation(s)
must be present in the system. You can find the link to the Level Zero spec in
the following section <a class="reference internal" href="#find-more">Find More</a>.</p>
<p>The Level Zero RT for <code class="docutils literal notranslate"><span class="pre">GPU</span></code>, OpenCL RT for <code class="docutils literal notranslate"><span class="pre">GPU</span></code>, OpenCL RT for <code class="docutils literal notranslate"><span class="pre">CPU</span></code>, FPGA
emulation RT and TBB runtime which are needed to run DPC++ application
on Intel <code class="docutils literal notranslate"><span class="pre">GPU</span></code> or Intel <code class="docutils literal notranslate"><span class="pre">CPU</span></code> devices can be downloaded using links in
<a class="reference download internal" download="" href="_downloads/8f566db736d384688b3abeedf2fb48f2/dependencies.json"><span class="xref download myst">the dependency configuration file</span></a>
and installed following the instructions below. The same versions are used in
PR testing.</p>
<p><strong>Linux</strong>:</p>
<ol class="arabic">
<li><p>Extract the archive. For example, for the archives
<code class="docutils literal notranslate"><span class="pre">oclcpuexp_&lt;cpu_version&gt;.tar.gz</span></code> and <code class="docutils literal notranslate"><span class="pre">fpgaemu_&lt;fpga_version&gt;.tar.gz</span></code> you would
run the following commands</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Extract OpenCL FPGA emulation RT</span>
mkdir<span class="w"> </span>-p<span class="w"> </span>/opt/intel/oclfpgaemu_&lt;fpga_version&gt;
<span class="nb">cd</span><span class="w"> </span>/opt/intel/oclfpgaemu_&lt;fpga_version&gt;
tar<span class="w"> </span>zxvf<span class="w"> </span>fpgaemu_&lt;fpga_version&gt;.tar.gz
<span class="c1"># Extract OpenCL CPU RT</span>
mkdir<span class="w"> </span>-p<span class="w"> </span>/opt/intel/oclcpuexp_&lt;cpu_version&gt;
<span class="nb">cd</span><span class="w"> </span>/opt/intel/oclcpuexp_&lt;cpu_version&gt;
tar<span class="w"> </span>-zxvf<span class="w"> </span>oclcpuexp_&lt;cpu_version&gt;.tar.gz
</pre></div>
</div>
</li>
<li><p>Create ICD file pointing to the new runtime (requires sudo access)</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># OpenCL FPGA emulation RT</span>
<span class="nb">echo</span><span class="w">  </span>/opt/intel/oclfpgaemu_&lt;fpga_version&gt;/x64/libintelocl_emu.so<span class="w"> </span><span class="p">|</span><span class="w"> </span>sudo<span class="w"> </span>tee
<span class="w">  </span>/etc/OpenCL/vendors/intel_fpgaemu.icd
<span class="c1"># OpenCL CPU RT</span>
<span class="nb">echo</span><span class="w"> </span>/opt/intel/oclcpuexp_&lt;cpu_version&gt;/x64/libintelocl.so<span class="w"> </span><span class="p">|</span><span class="w"> </span>sudo<span class="w"> </span>tee
<span class="w">  </span>/etc/OpenCL/vendors/intel_expcpu.icd
</pre></div>
</div>
</li>
<li><p>Extract or build TBB libraries using links in
<a class="reference download internal" download="" href="_downloads/8f566db736d384688b3abeedf2fb48f2/dependencies.json"><span class="xref download myst">the dependency configuration file</span></a>. For example,
for the archive oneapi-tbb-&lt;tbb_version&gt;-lin.tgz:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>-p<span class="w"> </span>/opt/intel
<span class="nb">cd</span><span class="w"> </span>/opt/intel
tar<span class="w"> </span>-zxvf<span class="w"> </span>oneapi-tbb*lin.tgz
</pre></div>
</div>
</li>
<li><p>Copy files from or create symbolic links to TBB libraries in OpenCL RT
folder:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># OpenCL FPGA emulation RT</span>
ln<span class="w"> </span>-s<span class="w"> </span>/opt/intel/oneapi-tbb-&lt;tbb_version&gt;/lib/intel64/gcc4.8/libtbb.so
<span class="w">  </span>/opt/intel/oclfpgaemu_&lt;fpga_version&gt;/x64/libtbb.so
ln<span class="w"> </span>-s<span class="w"> </span>/opt/intel/oneapi-tbb-&lt;tbb_version&gt;/lib/intel64/gcc4.8/libtbbmalloc.so
<span class="w">  </span>/opt/intel/oclfpgaemu_&lt;fpga_version&gt;/x64/libtbbmalloc.so
ln<span class="w"> </span>-s<span class="w"> </span>/opt/intel/oneapi-tbb-&lt;tbb_version&gt;/lib/intel64/gcc4.8/libtbb.so.12
<span class="w">  </span>/opt/intel/oclfpgaemu_&lt;fpga_version&gt;/x64/libtbb.so.12
ln<span class="w"> </span>-s<span class="w"> </span>/opt/intel/oneapi-tbb-&lt;tbb_version&gt;/lib/intel64/gcc4.8/libtbbmalloc.so.2
<span class="w">  </span>/opt/intel/oclfpgaemu_&lt;fpga_version&gt;/x64/libtbbmalloc.so.2
<span class="c1"># OpenCL CPU RT</span>
ln<span class="w"> </span>-s<span class="w"> </span>/opt/intel/oneapi-tbb-&lt;tbb_version&gt;/lib/intel64/gcc4.8/libtbb.so
<span class="w">  </span>/opt/intel/oclcpuexp_&lt;cpu_version&gt;/x64/libtbb.so
ln<span class="w"> </span>-s<span class="w"> </span>/opt/intel/oneapi-tbb-&lt;tbb_version&gt;/lib/intel64/gcc4.8/libtbbmalloc.so
<span class="w">  </span>/opt/intel/oclcpuexp_&lt;cpu_version&gt;/x64/libtbbmalloc.so
ln<span class="w"> </span>-s<span class="w"> </span>/opt/intel/oneapi-tbb-&lt;tbb_version&gt;/lib/intel64/gcc4.8/libtbb.so.12
<span class="w">  </span>/opt/intel/oclcpuexp_&lt;cpu_version&gt;/x64/libtbb.so.12
ln<span class="w"> </span>-s<span class="w"> </span>/opt/intel/oneapi-tbb-&lt;tbb_version&gt;/lib/intel64/gcc4.8/libtbbmalloc.so.2
<span class="w">  </span>/opt/intel/oclcpuexp_&lt;cpu_version&gt;/x64/libtbbmalloc.so.2
</pre></div>
</div>
</li>
<li><p>Configure library paths (requires sudo access)</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">echo</span><span class="w"> </span>/opt/intel/oclfpgaemu_&lt;fpga_version&gt;/x64<span class="w"> </span><span class="p">|</span><span class="w"> </span>sudo<span class="w"> </span>tee
<span class="w">  </span>/etc/ld.so.conf.d/libintelopenclexp.conf
<span class="nb">echo</span><span class="w"> </span>/opt/intel/oclcpuexp_&lt;cpu_version&gt;/x64<span class="w"> </span><span class="p">|</span><span class="w"> </span>sudo<span class="w"> </span>tee<span class="w"> </span>-a
<span class="w">  </span>/etc/ld.so.conf.d/libintelopenclexp.conf
sudo<span class="w"> </span>ldconfig<span class="w"> </span>-f<span class="w"> </span>/etc/ld.so.conf.d/libintelopenclexp.conf
</pre></div>
</div>
</li>
</ol>
<p><strong>Windows (64-bit)</strong>:</p>
<ol class="arabic">
<li><p>If you need OpenCL runtime for Intel <code class="docutils literal notranslate"><span class="pre">GPU</span></code> as well, then update/install it
first. Do it <strong>before</strong> installing OpenCL runtime for Intel <code class="docutils literal notranslate"><span class="pre">CPU</span></code> runtime as
OpenCL runtime for Intel <code class="docutils literal notranslate"><span class="pre">GPU</span></code> installer may re-write some important
files or settings and make existing OpenCL runtime for Intel <code class="docutils literal notranslate"><span class="pre">CPU</span></code> runtime
not working properly.</p></li>
<li><p>Extract the archive with OpenCL runtime for Intel <code class="docutils literal notranslate"><span class="pre">CPU</span></code> and/or for Intel
<code class="docutils literal notranslate"><span class="pre">FPGA</span></code> emulation using links in
<a class="reference download internal" download="" href="_downloads/8f566db736d384688b3abeedf2fb48f2/dependencies.json"><span class="xref download myst">the dependency configuration file</span></a>.  For
example, to <code class="docutils literal notranslate"><span class="pre">c:\oclcpu_rt_&lt;cpu_version&gt;</span></code>.</p></li>
<li><p>Extract the archive with TBB runtime or build it from sources using links
in <a class="reference download internal" download="" href="_downloads/8f566db736d384688b3abeedf2fb48f2/dependencies.json"><span class="xref download myst">the dependency configuration file</span></a>.  For
example, to <code class="docutils literal notranslate"><span class="pre">c:\oneapi-tbb-&lt;tbb_version&gt;</span></code>.</p></li>
<li><p>Run <code class="docutils literal notranslate"><span class="pre">Command</span> <span class="pre">Prompt</span></code> as <code class="docutils literal notranslate"><span class="pre">Administrator</span></code>. To do that click <code class="docutils literal notranslate"><span class="pre">Start</span></code> button,
type <code class="docutils literal notranslate"><span class="pre">Command</span> <span class="pre">Prompt</span></code>, click the Right mouse button on it, then click
<code class="docutils literal notranslate"><span class="pre">Run</span> <span class="pre">As</span> <span class="pre">Administrator</span></code>, then click <code class="docutils literal notranslate"><span class="pre">Yes</span></code> to confirm.</p></li>
<li><p>In the opened windows run <code class="docutils literal notranslate"><span class="pre">install.bat</span></code> provided with the extracted files
to install runtime to the system and setup environment variables. So, if the
extracted files are in <code class="docutils literal notranslate"><span class="pre">c:\oclcpu_rt_&lt;cpu_version&gt;\</span></code> folder, then type the
command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Install OpenCL FPGA emulation RT</span>
<span class="c1"># Answer Y to clean previous OCL_ICD_FILENAMES configuration and ICD records cleanup</span>
c:<span class="se">\o</span>clfpga_rt_&lt;fpga_version&gt;<span class="se">\i</span>nstall.bat<span class="w"> </span>c:<span class="se">\o</span>neapi-tbb-&lt;tbb_version&gt;<span class="se">\r</span>edist<span class="se">\i</span>ntel64<span class="se">\v</span>c14
<span class="c1"># Install OpenCL CPU RT</span>
<span class="c1"># Answer N for ICD records cleanup</span>
c:<span class="se">\o</span>clcpu_rt_&lt;cpu_version&gt;<span class="se">\i</span>nstall.bat<span class="w"> </span>c:<span class="se">\o</span>neapi-tbb-&lt;tbb_version&gt;<span class="se">\r</span>edist<span class="se">\i</span>ntel64<span class="se">\v</span>c14
</pre></div>
</div>
</li>
</ol>
</section>
<section id="obtain-prerequisites-for-ahead-of-time-aot-compilation">
<h3>Obtain prerequisites for ahead of time (AOT) compilation<a class="headerlink" href="#obtain-prerequisites-for-ahead-of-time-aot-compilation" title="Link to this heading">¶</a></h3>
<p><a class="reference internal" href="design/CompilerAndRuntimeDesign.html#ahead-of-time-aot-compilation"><span class="std std-ref">Ahead of time compilation</span></a>
requires ahead of time compiler available in <code class="docutils literal notranslate"><span class="pre">PATH</span></code>. There is
AOT compiler for each device type:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">GPU</span></code>, Level Zero and OpenCL runtimes are supported,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">CPU</span></code>, OpenCL runtime is supported,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Accelerator</span></code> (FPGA or FPGA emulation), OpenCL runtime is supported.</p></li>
</ul>
<section id="gpu">
<h4>GPU<a class="headerlink" href="#gpu" title="Link to this heading">¶</a></h4>
<ul>
<li><p>Linux</p>
<p>There are two ways how to obtain GPU AOT compiler <code class="docutils literal notranslate"><span class="pre">ocloc</span></code>:</p>
<ul class="simple">
<li><p>(Ubuntu) Download and install intel-ocloc_***.deb package from
<a class="reference external" href="https://github.com/intel/compute-runtime/releases">intel/compute-runtime releases</a>.
This package should have the same version as Level Zero / OpenCL GPU
runtimes installed on the system.</p></li>
<li><p>(other distros) <code class="docutils literal notranslate"><span class="pre">ocloc</span></code> is a part of
<a class="reference external" href="https://dgpu-docs.intel.com/index.html">Intel® software packages for general purpose GPU capabilities</a>.</p></li>
</ul>
</li>
<li><p>Windows</p>
<ul class="simple">
<li><p>GPU AOT compiler <code class="docutils literal notranslate"><span class="pre">ocloc</span></code> is a part of
<a class="reference external" href="https://software.intel.com/content/www/us/en/develop/tools/oneapi/base-toolkit.html">Intel® oneAPI Base Toolkit</a>
(Intel® oneAPI DPC++/C++ Compiler component).<br />
Make sure that the following path to <code class="docutils literal notranslate"><span class="pre">ocloc</span></code> binary is available in <code class="docutils literal notranslate"><span class="pre">PATH</span></code>
environment variable:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">&lt;oneAPI</span> <span class="pre">installation</span> <span class="pre">location&gt;/compiler/&lt;version&gt;/windows/lib/ocloc</span></code></p></li>
</ul>
</li>
</ul>
</li>
</ul>
</section>
<section id="cpu">
<h4>CPU<a class="headerlink" href="#cpu" title="Link to this heading">¶</a></h4>
<ul class="simple">
<li><p>CPU AOT compiler <code class="docutils literal notranslate"><span class="pre">opencl-aot</span></code> is enabled by default. For more, see
<a class="reference external" href="https://github.com/intel/llvm/blob/sycl/opencl/opencl-aot/README.md">opencl-aot documentation</a>.</p></li>
</ul>
</section>
<section id="accelerator">
<h4>Accelerator<a class="headerlink" href="#accelerator" title="Link to this heading">¶</a></h4>
<ul class="simple">
<li><p>Accelerator AOT compiler <code class="docutils literal notranslate"><span class="pre">aoc</span></code> is a part of
<a class="reference external" href="https://software.intel.com/content/www/us/en/develop/tools/oneapi/base-toolkit.html">Intel® oneAPI Base Toolkit</a>
(Intel® oneAPI DPC++/C++ Compiler component).<br />
Make sure that these binaries are available in <code class="docutils literal notranslate"><span class="pre">PATH</span></code> environment variable:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">aoc</span></code> from <code class="docutils literal notranslate"><span class="pre">&lt;oneAPI</span> <span class="pre">installation</span> <span class="pre">location&gt;/compiler/&lt;version&gt;/&lt;OS&gt;/lib/oclfpga/bin</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">aocl-ioc64</span></code> from <code class="docutils literal notranslate"><span class="pre">&lt;oneAPI</span> <span class="pre">installation</span> <span class="pre">location&gt;/compiler/&lt;version&gt;/&lt;OS&gt;/bin</span></code></p></li>
</ul>
</li>
</ul>
</section>
</section>
<section id="test-dpc-toolchain">
<h3>Test DPC++ toolchain<a class="headerlink" href="#test-dpc-toolchain" title="Link to this heading">¶</a></h3>
<section id="run-in-tree-lit-tests">
<h4>Run in-tree LIT tests<a class="headerlink" href="#run-in-tree-lit-tests" title="Link to this heading">¶</a></h4>
<p>To verify that built DPC++ toolchain is working correctly, run:</p>
<p><strong>Linux</strong>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span><span class="nv">$DPCPP_HOME</span>/llvm/buildbot/check.py
</pre></div>
</div>
<p><strong>Windows (64-bit)</strong>:</p>
<div class="highlight-bat notranslate"><div class="highlight"><pre><span></span>python <span class="nv">%DPCPP_HOME%</span>\llvm\buildbot\check.py
</pre></div>
</div>
<p>Make sure that psutil package is installed.
If no OpenCL GPU/CPU runtimes are available, the corresponding tests are
skipped.</p>
<p>If CUDA support has been built, it is tested only if there are CUDA devices
available.</p>
<p>If testing with HIP for AMD, the lit tests will use <code class="docutils literal notranslate"><span class="pre">gfx906</span></code> as the default
architecture. It is possible to change it by adding
<code class="docutils literal notranslate"><span class="pre">-Xsycl-target-backend=amdgcn-amd-amdhsa</span> <span class="pre">--offload-arch=&lt;target&gt;</span></code> to the CMake
variable <code class="docutils literal notranslate"><span class="pre">SYCL_CLANG_EXTRA_FLAGS</span></code>.</p>
</section>
<section id="run-dpc-e2e-tests">
<h4>Run DPC++ E2E tests<a class="headerlink" href="#run-dpc-e2e-tests" title="Link to this heading">¶</a></h4>
<p>Follow instructions from the link below to build and run tests:
<a class="reference external" href="https://github.com/intel/llvm/blob/sycl/sycl/test-e2e/README.md#build-and-run-tests">README</a></p>
</section>
<section id="run-khronos-sycl-conformance-test-suite-optional">
<h4>Run Khronos* SYCL* conformance test suite (optional)<a class="headerlink" href="#run-khronos-sycl-conformance-test-suite-optional" title="Link to this heading">¶</a></h4>
<p>Khronos* SYCL* conformance test suite (CTS) is intended to validate
implementation conformance to Khronos* SYCL* specification. DPC++ compiler is
expected to pass significant number of tests, and it keeps improving.</p>
<p>Follow Khronos* SYCL* CTS instructions from
<a class="reference external" href="https://github.com/KhronosGroup/SYCL-CTS#configuration--compilation">README</a>
file to obtain test sources and instructions how build and execute the tests.</p>
</section>
</section>
<section id="run-simple-dpc-application">
<h3>Run simple DPC++ application<a class="headerlink" href="#run-simple-dpc-application" title="Link to this heading">¶</a></h3>
<p>A simple DPC++ or SYCL* program consists of following parts:</p>
<ol class="arabic simple">
<li><p>Header section</p></li>
<li><p>Allocating buffer for data</p></li>
<li><p>Creating SYCL queue</p></li>
<li><p>Submitting command group to SYCL queue which includes the kernel</p></li>
<li><p>Wait for the queue to complete the work</p></li>
<li><p>Use buffer accessor to retrieve the result on the device and verify the data</p></li>
<li><p>The end</p></li>
</ol>
<p>Creating a file <code class="docutils literal notranslate"><span class="pre">simple-sycl-app.cpp</span></code> with the following C++/SYCL code:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;sycl/sycl.hpp&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">// Creating buffer of 4 elements to be used inside the kernel code</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">buffer</span><span class="o">&lt;</span><span class="kt">size_t</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Buffer</span><span class="p">(</span><span class="mi">4</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Creating SYCL queue</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">queue</span><span class="w"> </span><span class="n">Queue</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Size of index space for kernel</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">range</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="w"> </span><span class="n">NumOfWorkItems</span><span class="p">{</span><span class="n">Buffer</span><span class="p">.</span><span class="n">size</span><span class="p">()};</span>

<span class="w">  </span><span class="c1">// Submitting command group(work) to queue</span>
<span class="w">  </span><span class="n">Queue</span><span class="p">.</span><span class="n">submit</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">handler</span><span class="w"> </span><span class="o">&amp;</span><span class="n">cgh</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// Getting write only access to the buffer on a device.</span>
<span class="w">    </span><span class="n">sycl</span><span class="o">::</span><span class="n">accessor</span><span class="w"> </span><span class="n">Accessor</span><span class="p">{</span><span class="n">Buffer</span><span class="p">,</span><span class="w"> </span><span class="n">cgh</span><span class="p">,</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">write_only</span><span class="p">};</span>
<span class="w">    </span><span class="c1">// Executing kernel</span>
<span class="w">    </span><span class="n">cgh</span><span class="p">.</span><span class="n">parallel_for</span><span class="o">&lt;</span><span class="k">class</span><span class="w"> </span><span class="nc">FillBuffer</span><span class="o">&gt;</span><span class="p">(</span>
<span class="w">        </span><span class="n">NumOfWorkItems</span><span class="p">,</span><span class="w"> </span><span class="p">[</span><span class="o">=</span><span class="p">](</span><span class="n">sycl</span><span class="o">::</span><span class="n">id</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="w"> </span><span class="n">WIid</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">          </span><span class="c1">// Fill buffer with indexes.</span>
<span class="w">          </span><span class="n">Accessor</span><span class="p">[</span><span class="n">WIid</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">WIid</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="w">        </span><span class="p">});</span>
<span class="w">  </span><span class="p">});</span>

<span class="w">  </span><span class="c1">// Getting read only access to the buffer on the host.</span>
<span class="w">  </span><span class="c1">// Implicit barrier waiting for queue to complete the work.</span>
<span class="w">  </span><span class="n">sycl</span><span class="o">::</span><span class="n">host_accessor</span><span class="w"> </span><span class="n">HostAccessor</span><span class="p">{</span><span class="n">Buffer</span><span class="p">,</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">read_only</span><span class="p">};</span>

<span class="w">  </span><span class="c1">// Check the results</span>
<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="n">MismatchFound</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">false</span><span class="p">;</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">size_t</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">Buffer</span><span class="p">.</span><span class="n">size</span><span class="p">();</span><span class="w"> </span><span class="o">++</span><span class="n">I</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">HostAccessor</span><span class="p">[</span><span class="n">I</span><span class="p">]</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">I</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;The result is incorrect for element: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">I</span>
<span class="w">                </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; , expected: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; , got: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">HostAccessor</span><span class="p">[</span><span class="n">I</span><span class="p">]</span>
<span class="w">                </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">      </span><span class="n">MismatchFound</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">true</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">MismatchFound</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;The results are correct!&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">MismatchFound</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>To build simple-sycl-app put <code class="docutils literal notranslate"><span class="pre">bin</span></code> and <code class="docutils literal notranslate"><span class="pre">lib</span></code> to PATHs:</p>
<p><strong>Linux</strong>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">PATH</span><span class="o">=</span><span class="nv">$DPCPP_HOME</span>/llvm/build/bin:<span class="nv">$PATH</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="nv">$DPCPP_HOME</span>/llvm/build/lib:<span class="nv">$LD_LIBRARY_PATH</span>
</pre></div>
</div>
<p><strong>Windows (64-bit)</strong>:</p>
<div class="highlight-bat notranslate"><div class="highlight"><pre><span></span><span class="k">set</span> <span class="nv">PATH</span><span class="p">=</span><span class="nv">%DPCPP_HOME%</span>\llvm\build\bin;<span class="nv">%PATH%</span>
<span class="k">set</span> <span class="nv">LIB</span><span class="p">=</span><span class="nv">%DPCPP_HOME%</span>\llvm\build\lib;<span class="nv">%LIB%</span>
</pre></div>
</div>
<p>and run following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>clang++<span class="w"> </span>-fsycl<span class="w"> </span>simple-sycl-app.cpp<span class="w"> </span>-o<span class="w"> </span>simple-sycl-app.exe
</pre></div>
</div>
<p>When building for CUDA or HIP NVIDIA, use the CUDA target triple as follows:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>clang++<span class="w"> </span>-fsycl<span class="w"> </span>-fsycl-targets<span class="o">=</span>nvptx64-nvidia-cuda<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>simple-sycl-app.cpp<span class="w"> </span>-o<span class="w"> </span>simple-sycl-app-cuda.exe
</pre></div>
</div>
<p><strong>Linux &amp; Windows (64-bit)</strong>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./simple-sycl-app.exe
The<span class="w"> </span>results<span class="w"> </span>are<span class="w"> </span>correct!
</pre></div>
</div>
<p><strong>NOTE</strong>: Currently, when the application has been built with the CUDA target,
the CUDA backend must be selected at runtime using the <code class="docutils literal notranslate"><span class="pre">ONEAPI_DEVICE_SELECTOR</span></code>
environment variable.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">ONEAPI_DEVICE_SELECTOR</span><span class="o">=</span>cuda:*<span class="w"> </span>./simple-sycl-app-cuda.exe
</pre></div>
</div>
<p><strong>NOTE</strong>: oneAPI DPC++/SYCL developers can specify SYCL device for execution
using device selectors (e.g. <code class="docutils literal notranslate"><span class="pre">sycl::cpu_selector_v</span></code>, <code class="docutils literal notranslate"><span class="pre">sycl::gpu_selector_v</span></code>,
<a class="reference download internal" download="" href="_downloads/ac544d7df547b08010cf2d8aa61e8f79/sycl_ext_intel_fpga_device_selector.asciidoc"><span class="xref download myst">Intel FPGA selector(s)</span></a>)
as explained in following section
<a class="reference internal" href="#code-the-program-for-a-specific-gpu">Code the program for a specific GPU</a>.</p>
<section id="aot-target-architectures">
<h4>AOT Target architectures<a class="headerlink" href="#aot-target-architectures" title="Link to this heading">¶</a></h4>
<p><strong>NOTE</strong>: When building for HIP AMD, you <strong>MUST</strong> use the AMD target triple and
specify the target architecture with
<code class="docutils literal notranslate"><span class="pre">-Xsycl-target-backend</span> <span class="pre">--offload-arch=&lt;arch&gt;</span></code> as follows:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>clang++<span class="w"> </span>-fsycl<span class="w"> </span>-fsycl-targets<span class="o">=</span>amdgcn-amd-amdhsa<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-Xsycl-target-backend<span class="w"> </span>--offload-arch<span class="o">=</span>gfx906<span class="w">              </span><span class="se">\</span>
<span class="w">  </span>simple-sycl-app.cpp<span class="w"> </span>-o<span class="w"> </span>simple-sycl-app-amd.exe
</pre></div>
</div>
<p>The target architecture may also be specified for the CUDA backend, with
<code class="docutils literal notranslate"><span class="pre">-Xsycl-target-backend</span> <span class="pre">--cuda-gpu-arch=&lt;arch&gt;</span></code>. Specifying the architecture is
necessary if an application aims to use newer hardware features, such as
native atomic operations or the joint_matrix extension.
Moreover, it is possible to pass specific options to CUDA <code class="docutils literal notranslate"><span class="pre">ptxas</span></code> (such as
<code class="docutils literal notranslate"><span class="pre">--maxrregcount=&lt;n&gt;</span></code> for limiting the register usage or <code class="docutils literal notranslate"><span class="pre">--verbose</span></code> for
printing generation statistics) using the <code class="docutils literal notranslate"><span class="pre">-Xcuda-ptxas</span></code> flag.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>clang++<span class="w"> </span>-fsycl<span class="w"> </span>-fsycl-targets<span class="o">=</span>nvptx64-nvidia-cuda<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>simple-sycl-app.cpp<span class="w"> </span>-o<span class="w"> </span>simple-sycl-app-cuda.exe<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-Xcuda-ptxas<span class="w"> </span>--maxrregcount<span class="o">=</span><span class="m">128</span><span class="w"> </span>-Xcuda-ptxas<span class="w"> </span>--verbose<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-Xsycl-target-backend<span class="w"> </span>--cuda-gpu-arch<span class="o">=</span>sm_80
</pre></div>
</div>
<p>To build simple-sycl-app ahead of time for GPU, CPU or Accelerator devices,
specify the target architecture.  The examples provided use a supported
alias for the target, representing a full triple.  Additional details can
be found in the <a class="reference internal" href="UsersManual.html#generic-options"><span class="std std-ref">Users Manual</span></a>.</p>
<p><code class="docutils literal notranslate"><span class="pre">-fsycl-targets=spir64_gen</span></code> for GPU,
<code class="docutils literal notranslate"><span class="pre">-fsycl-targets=spir64_x86_64</span></code> for CPU,
<code class="docutils literal notranslate"><span class="pre">-fsycl-targets=spir64_fpga</span></code> for Accelerator.</p>
<p>Multiple target architectures are supported.</p>
<p>E.g., this command builds simple-sycl-app for GPU and CPU devices in
ahead of time mode:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>clang++<span class="w"> </span>-fsycl<span class="w"> </span>-fsycl-targets<span class="o">=</span>spir64_gen,spir64_x86_64<span class="w"> </span>simple-sycl-app.cpp<span class="w"> </span>-o<span class="w"> </span>simple-sycl-app-aot.exe
</pre></div>
</div>
<p>Additionally, user can pass specific options of AOT compiler to
the DPC++ compiler using <code class="docutils literal notranslate"><span class="pre">-Xsycl-target-backend</span></code> option, see
<a class="reference internal" href="design/CompilerAndRuntimeDesign.html#device-code-formats"><span class="std std-ref">Device code formats</span></a> for
more. To find available options, execute:</p>
<p><code class="docutils literal notranslate"><span class="pre">ocloc</span> <span class="pre">compile</span> <span class="pre">--help</span></code> for GPU,
<code class="docutils literal notranslate"><span class="pre">opencl-aot</span> <span class="pre">--help</span></code> for CPU,
<code class="docutils literal notranslate"><span class="pre">aoc</span> <span class="pre">-help</span> <span class="pre">-sycl</span></code> for Accelerator.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">simple-sycl-app.exe</span></code> application doesn’t specify SYCL device for
execution, so SYCL runtime will use <code class="docutils literal notranslate"><span class="pre">default_selector</span></code> logic to select one
of accelerators available in the system.
In this case, the behavior of the <code class="docutils literal notranslate"><span class="pre">default_selector</span></code> can be altered
using the <code class="docutils literal notranslate"><span class="pre">ONEAPI_DEVICE_SELECTOR</span></code> environment variable, setting <code class="docutils literal notranslate"><span class="pre">cuda:*</span></code> forces
the usage of the CUDA backend (if available), <code class="docutils literal notranslate"><span class="pre">hip:*</span></code> forces
the usage of the HIP backend (if available), <code class="docutils literal notranslate"><span class="pre">opencl:*</span></code> will
force the usage of the OpenCL backend.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">ONEAPI_DEVICE_SELECTOR</span><span class="o">=</span>cuda:*<span class="w"> </span>./simple-sycl-app-cuda.exe
</pre></div>
</div>
<p>The default is the OpenCL backend if available.</p>
<p><strong>NOTE</strong>: <code class="docutils literal notranslate"><span class="pre">nvptx64-nvidia-cuda</span></code> is usable with <code class="docutils literal notranslate"><span class="pre">-fsycl-targets</span></code>
if clang was built with the cmake option <code class="docutils literal notranslate"><span class="pre">SYCL_ENABLE_BACKENDS=cuda</span></code>.</p>
</section>
</section>
<section id="build-dpc-application-with-cmake">
<h3>Build DPC++ application with CMake<a class="headerlink" href="#build-dpc-application-with-cmake" title="Link to this heading">¶</a></h3>
<p>DPC++ applications can be built with CMake by simply using DPC++ as the C++
compiler and by adding the SYCL specific flags. For example assuming <code class="docutils literal notranslate"><span class="pre">clang++</span></code>
is on the <code class="docutils literal notranslate"><span class="pre">PATH</span></code>, a minimal <code class="docutils literal notranslate"><span class="pre">CMakeLists.txt</span></code> file for the sample above would be:</p>
<div class="highlight-cmake notranslate"><div class="highlight"><pre><span></span><span class="c"># Modifying the compiler should be done before the project line</span>
<span class="nb">set</span><span class="p">(</span><span class="s">CMAKE_CXX_COMPILER</span><span class="w"> </span><span class="s2">&quot;clang++&quot;</span><span class="p">)</span>
<span class="nb">set</span><span class="p">(</span><span class="s">CMAKE_CXX_FLAGS</span><span class="w"> </span><span class="s2">&quot;${CMAKE_CXX_FLAGS} -fsycl&quot;</span><span class="p">)</span>

<span class="nb">project</span><span class="p">(</span><span class="s">simple-sycl-app</span><span class="w"> </span><span class="s">LANGUAGES</span><span class="w"> </span><span class="s">CXX</span><span class="p">)</span>

<span class="nb">add_executable</span><span class="p">(</span><span class="s">simple-sycl-app</span><span class="w"> </span><span class="s">simple-sycl-app.cpp</span><span class="p">)</span>
</pre></div>
</div>
<p>NOTE: compiling SYCL programs requires passing the SYCL flags to <code class="docutils literal notranslate"><span class="pre">clang++</span></code> for
both the compilation and linking stages, so using <code class="docutils literal notranslate"><span class="pre">add_compile_options</span></code> to pass
the SYCL flags is not enough on its own, they should also be passed to
<code class="docutils literal notranslate"><span class="pre">add_link_options</span></code>, or more simply the SYCL flags can just be added to
<code class="docutils literal notranslate"><span class="pre">CMAKE_CXX_FLAGS</span></code>.</p>
<p>NOTE: When linking a SYCL application, <code class="docutils literal notranslate"><span class="pre">clang++</span></code> will implicitly link it against
<code class="docutils literal notranslate"><span class="pre">libsycl.so</span></code>, so there is no need to add <code class="docutils literal notranslate"><span class="pre">-lsycl</span></code> to <code class="docutils literal notranslate"><span class="pre">target_link_libraries</span></code> in
the CMake.</p>
</section>
<section id="code-the-program-for-a-specific-gpu">
<h3>Code the program for a specific GPU<a class="headerlink" href="#code-the-program-for-a-specific-gpu" title="Link to this heading">¶</a></h3>
<p>To assist in finding a specific SYCL compatible device out of all that may be
available, a “device selector” may be used. A “device selector” is a ranking
function (C++ Callable) that will give an integer ranking value to all the
devices on the system. It can be passed to <code class="docutils literal notranslate"><span class="pre">sycl::queue</span></code>, <code class="docutils literal notranslate"><span class="pre">sycl::device</span></code> and
<code class="docutils literal notranslate"><span class="pre">sycl::platform</span></code> constructors. The highest ranking device is then selected. SYCL
has built-in device selectors for selecting a generic GPU, CPU, or accelerator
device, as well as one for a default device. Additionally, a user can define
their own as function, lambda, or functor class. Device selectors returning
negative values will “reject” a device ensuring it is not selected, but values 0
or higher will be selected by the highest score with ties resolved by an
internal algorithm (see Section 4.6.1 of the SYCL 2020 specification)</p>
<p>The example below illustrates how to use a device selector to create device and
queue objects bound to Intel GPU device:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;sycl/sycl.hpp&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>

<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">NEOGPUDeviceSelector</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[](</span><span class="k">const</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">device</span><span class="w"> </span><span class="o">&amp;</span><span class="n">Device</span><span class="p">){</span>
<span class="w">    </span><span class="k">using</span><span class="w"> </span><span class="k">namespace</span><span class="w"> </span><span class="nn">sycl</span><span class="o">::</span><span class="nn">info</span><span class="p">;</span>

<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="n">DeviceName</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Device</span><span class="p">.</span><span class="n">get_info</span><span class="o">&lt;</span><span class="n">device</span><span class="o">::</span><span class="n">name</span><span class="o">&gt;</span><span class="p">();</span>
<span class="w">    </span><span class="kt">bool</span><span class="w"> </span><span class="n">match</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Device</span><span class="p">.</span><span class="n">is_gpu</span><span class="p">()</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="p">(</span><span class="n">DeviceName</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="s">&quot;HD Graphics NEO&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">::</span><span class="n">npos</span><span class="p">);</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">match</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="mi">-1</span><span class="p">;</span>
<span class="w">  </span><span class="p">};</span>

<span class="w">  </span><span class="k">try</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">sycl</span><span class="o">::</span><span class="n">queue</span><span class="w"> </span><span class="nf">Queue</span><span class="p">(</span><span class="n">NEOGPUDeviceSelector</span><span class="p">);</span>
<span class="w">    </span><span class="n">sycl</span><span class="o">::</span><span class="n">device</span><span class="w"> </span><span class="nf">Device</span><span class="p">(</span><span class="n">NEOGPUDeviceSelector</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span><span class="w"> </span><span class="k">catch</span><span class="w"> </span><span class="p">(</span><span class="n">sycl</span><span class="o">::</span><span class="n">exception</span><span class="w"> </span><span class="o">&amp;</span><span class="n">E</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">E</span><span class="p">.</span><span class="n">what</span><span class="p">()</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The device selector below selects an NVIDIA device only, and won’t execute if
there is none.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="w"> </span><span class="nf">CUDASelector</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">sycl</span><span class="o">::</span><span class="n">device</span><span class="w"> </span><span class="o">&amp;</span><span class="n">Device</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">using</span><span class="w"> </span><span class="k">namespace</span><span class="w"> </span><span class="nn">sycl</span><span class="o">::</span><span class="nn">info</span><span class="p">;</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="w"> </span><span class="n">DriverVersion</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Device</span><span class="p">.</span><span class="n">get_info</span><span class="o">&lt;</span><span class="n">device</span><span class="o">::</span><span class="n">driver_version</span><span class="o">&gt;</span><span class="p">();</span>

<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">Device</span><span class="p">.</span><span class="n">is_gpu</span><span class="p">()</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="p">(</span><span class="n">DriverVersion</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="s">&quot;CUDA&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">::</span><span class="n">npos</span><span class="p">))</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; CUDA device found &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">  </span><span class="p">};</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="mi">-1</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
</section>
<section id="c-standard">
<h2>C++ standard<a class="headerlink" href="#c-standard" title="Link to this heading">¶</a></h2>
<ul class="simple">
<li><p>DPC++ runtime and headers require C++17 at least.</p></li>
<li><p>DPC++ compiler builds apps as C++17 apps by default. Higher versions of
standard are supported as well.</p></li>
</ul>
</section>
<section id="known-issues-and-limitations">
<h2>Known Issues and Limitations<a class="headerlink" href="#known-issues-and-limitations" title="Link to this heading">¶</a></h2>
<ul class="simple">
<li><p>SYCL 2020 support work is in progress.</p></li>
<li><p>32-bit host/target is not supported.</p></li>
<li><p>DPC++ works only with OpenCL low level runtimes which support out-of-order
queues.</p></li>
<li><p>On Windows linking DPC++ applications with <code class="docutils literal notranslate"><span class="pre">/MTd</span></code> flag is known to cause
crashes.</p></li>
</ul>
<section id="cuda-back-end-limitations">
<h3>CUDA back-end limitations<a class="headerlink" href="#cuda-back-end-limitations" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p>Windows support is currently experimental and not regularly tested.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sycl::sqrt</span></code> is not correctly rounded by default as the SYCL specification
allows lower precision, when porting from CUDA it may be helpful to use
<code class="docutils literal notranslate"><span class="pre">-fsycl-fp32-prec-sqrt</span></code> to use the correctly rounded square root, this is
significantly slower but matches the default precision used by <code class="docutils literal notranslate"><span class="pre">nvcc</span></code>, and
this <code class="docutils literal notranslate"><span class="pre">clang++</span></code> flag is equivalent to the <code class="docutils literal notranslate"><span class="pre">nvcc</span></code> <code class="docutils literal notranslate"><span class="pre">-prec-sqrt</span></code> flag, except that
it defaults to <code class="docutils literal notranslate"><span class="pre">false</span></code>.</p></li>
<li><p>No Opt (O0) uses the IPSCCP compiler pass by default, although the IPSCCP pass
can be switched off at O0 using the <code class="docutils literal notranslate"><span class="pre">-mllvm</span> <span class="pre">-use-ipsccp-nvptx-O0=false</span></code> flag at
the user’s discretion.
The reason that the IPSCCP pass is used by default even at O0 is that there is
currently an unresolved issue with the nvvm-reflect compiler pass: This pass is
used to pick the correct branches depending on the SM version which can be
optionally specified by the <code class="docutils literal notranslate"><span class="pre">--cuda-gpu-arch</span></code> flag.
If the arch flag is not specified by the user, the default value, SM 50, is used.
Without the execution of the IPSCCP pass at -O0 when using a low SM version,
dead instructions which require a higher SM version can remain. Since
corresponding issues occur in other backends future work will aim for a
universal solution to these issues.</p></li>
</ul>
</section>
<section id="hip-back-end-limitations">
<h3>HIP back-end limitations<a class="headerlink" href="#hip-back-end-limitations" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p>Requires a ROCm compatible operating system, for full details of supported
Operating System for ROCm, please refer to the
<a class="reference external" href="https://github.com/RadeonOpenCompute/ROCm#supported-operating-systems">ROCm Supported Operating Systems</a>.</p></li>
<li><p>Support is still in a beta state, but the backend is being actively developed.</p></li>
<li><p>Global offsets are currently not supported.</p></li>
</ul>
</section>
</section>
<section id="find-more">
<h2>Find More<a class="headerlink" href="#find-more" title="Link to this heading">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://spec.oneapi.io/versions/latest/">oneAPI specifications</a></p></li>
<li><p><a class="reference external" href="https://www.khronos.org/registry/SYCL">SYCL* specification</a></p></li>
<li><p><a class="reference external" href="https://spec.oneapi.io/level-zero/latest/index.html">Level Zero specification</a></p></li>
</ul>
<p><sub>*Other names and brands may be claimed as the property of others.</sub></p>
</section>
</section>


      </div>
      <div class="bottomnav" role="navigation" aria-label="bottom navigation">
      
        <p>
        «&#160;&#160;<a href="index.html">DPC++ Documentation</a>
        &#160;&#160;::&#160;&#160;
        <a class="uplink" href="index.html">Contents</a>
        &#160;&#160;::&#160;&#160;
        <a href="UsersManual.html">Users Manual</a>&#160;&#160;»
        </p>

      </div>

    <div class="footer" role="contentinfo">
    &#169; Copyright 2024, Intel Corporation.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.3.7.
    </div>
  </body>
</html>